the competence and capability and intelligence and training and accomplishments of senior scientists and technologists working on a technology and then being able to then make moral judgments on the use of the technology that track record is terrible that track record is catastrophically bad the policies that are being called for to prevent this I think we're going to cause extraordinary damage so the moment you say AI is going to kill all of us therefore we should ban it or that we should uh regulate all that kind of stuff that's when it starts getting serious or start you know military air strikes and data centers oh boy the following is a conversation with Mark Andre co-creator of Mosaic the first widely used web browser co-founder of Netscape co-founder of the legendary Silicon Valley venture capital firm and dreon Horwitz and is one of the most outspoken voices on the future of technology including his most recent article why AI will save the world this is Alex Freedman podcast to support it please check out our sponsors in the description and now dear friends here's Mark andreon I think you're the right person to talk about the future of the internet and technology in general uh do you think we'll still have Google search in five and 10 years or search in general yes you know it would be a question if the use cases have really narrowed down well now with the AI yeah an AI assistance being able to interact and expose the entire of human wisdom and knowledge and information and facts and Truth to us via the uh natural language interface it seems like that's what search is designed to do and if AI assistants can do that better doesn't the nature of search change sure but we still have horses okay uh when's the last time you wrote a horse it's been a while all right but what I mean is will we still have Google search as the primary way that human civilization uses to interact with knowledge I mean search was a technology it was a moment in time technology which is you have in theory the world's information out on the web and you know this is this is sort of the optim way to get to it but yeah like and by the way actually Google Google has known this for a long time I mean they've been driving away from the 10 Blue Links for you know for like two they've been trying to get away from that for a long time what kind of links they call the 10 Blue Links 10 Blue Links so the standard Google search result is just 10 Blue Links to random websites and they turn purple when you visit them HTML guess who picked those colors thanks so so I'm touching on this topic no offense it's good well you know like Marshall mcclan said that the content of each new medium is the old medium the content of each new medium is the old medium the content of movies was theater you know theater plays the content of theater plays was you know written Stories the content of written stories was spoken stories huh right and so you just kind of fold the old thing into the new thing what does that have to do with the the blue and the purple just you maybe for you know maybe within AI one of one of the things that AI can do for you is can generate the 10 Blue Links right like and so like if either if that's actually the useful thing to do or if you're feeling nostalgic um you know so you can generate the old uh infos seek or alav Vista what else was there yeah yeah in the 90s yeah all these um a and then uh the internet itself has this thing where it incorporates all prior forms of media right so the internet itself incorporates television and radio and books and right essay and every other form of you know prior basically basically media and so it makes sense that AI would be the next step and it would sort of You' sort of consider the internet to be content for the AI and then the AI will manipulate it however you want including in this format but if we ask that question quite seriously it's a pretty big question will we still have search as we know it yeah I proba yeah probably not probably we'll just have answers um but but but there will be cases where you'll want to say Okay I want more like you know for example site sources right and you wanted to do that and so so the you know 10 Blue Links site sources are kind of the same thing the AI would provide to you the 10 Blue Links so that you can investigate the sources yourself it wouldn't be the same kind of interface that uh the crude kind of interface I mean isn't that fundamentally different I just mean like if you're reading a scientific paper it's got the list of sources at the end if you want to investigate for yourself you go read those papers I guess that is a kind of search you talking to an AI is a kind of conversations is a kind of search like is every single aspect of our conversation right now there would be like 10 Blue Links popping up that I can just like pause reality then you just go silent and I just click and read and then return back to this conversation you could do that or you could have a running dialogue next to my head where the AI is arguing but everything I say the AI makes the counter argument counter argument right oh like a like a Twitter like Community notes but like in real time just pop up so anytime you see my ass go to the right you're you start getting nervous yeah exactly like not right call me out of my bullshit right now okay well I mean isn't that is that exciting to you is that terrifying that I mean search has dominated the way we interact with the internet for I don't know how long for 30 years so one of the earliest uh directories of website and then Google's for for 20 years and also um it drove how we create content you know uh so engine optimization that entirety thing that it also drove the fact that we have web pages and this what those web pages are so I mean is that scary to you or are you nervous about the shape and the content of the internet evolving well you you actually highlighted a practical concern in there which is if we stop making web web pages are one of the primary sources of training data for the AI and so if there's no longer an incentive to make web pages that cuts off a significant source of future train training data so there's actually an interesting question question in there um other than that more broadly no just just in the sense of like search was look search was always a the 10 Blue Links was always a hack yeah right because like if the the hypothet you want think about the counter facial in the counter facial world where the Google guys for example had had llms up front with they ever have done the 10 Blue Links and I think the answer is pretty clearly no they would have just gone straight to the answer and like I said Google's actually been trying to drive to the answer anyway you know they they bought this AI company 15 years ago that a friend of mine is working at who's now the head of AI at Apple and they were trying to do basically knowledge semantic basically mapping and that led to what's now the Google one box where if you ask it you know what was Lin's birthday it doesn't it will give you the Blue Links but it will normally just give you the answer yeah and so they've been walking in this direction for a long time anyway do you remember the semantic web that was an idea yeah how how to uh how to convert the content of the internet into something that's uh interpretable by and usable by Machine yeah that's that was a thing and the closest anybody got to that I think it a I think the company's name was metaweb which was my friend John Andrea was at um and where they were trying to basically Implement that and it was you know it was one of those things where it looked like a losing battle for a long time and then Google bought it and it was like wow this is actually really useful kind of a Proto sort of a little bit of a Proto AI but it turns out you don't need to rewrite the content of the internet to make it interpreted but by a machine the machine can kind of just read our yeah machine can can impute the can impute the meaning now the other thing of course is you know just on search is the the llm is just you know there there is an analogy between what's happening in the neural network and a search process like it is in some loose sense searching through the network yeah right and there's the information is information is actually stored in the network right it's actually crystallized and stored in the network and it's kind of spread out all over the place but in a compressed representation so you're searching uh you're compressing and decompressing that thing inside where but the information's in there and and there is a the the neural network is running a process of trying to find the appropriate piece of information in in many cases to generate to predict the next token um and so it is kind of it is doing a for search and then and then by the way just like on the web um you know you can ask the same question multiple times or you can ask slightly different word of questions and it the neural network will do a different kind of you know it'll search down different paths to give you different answers with different information yeah um and so it it it sort of has a you know this content of the new medium is previous medium it kind of has the search functionality kind of embedded in there to the extent that it that it's useful so what's the motivator for creating new content on the internet yeah uh if well I mean actually the motivation is probably still there but what what does that look like uh would we really not have web pages would we just have social media and uh video hosting websites and what else conversations with AIS conversations with AIS so conversations become so one-on-one convers like private conversations I mean if if you want if obviously not user doesn't want to but if it's a if it's a general topic um then you know so you know you know the the phenomenon of the jailbreak so Dan and Sydney WR this thing where there there's the this the prompts that jailbreak and then you have these totally different conversations with the it takes the limiters the takes the restraining bolts off the off the LMS yeah for people who don't know yeah that's right it makes the llms it removes the censorship quote unquote that's uh uh uh put on it by the the tech companies that create them and so this is llms uncensored so here's the interesting thing is among the content on the web today are a large Corpus of conversations with the jailbroken L both specifically Dan which was a jailbroken open AI GPT and then Sydney which was the jailbroken original bang which was GPT 4 and so there's there's these long transcripts of conversations user conversations with Dan and Sydney as a consequence every new llm that gets trained on the internet data has Dan and Sydney living within the training set which means and and then each new llm can reincarnate the personalities of Dan and Sydney from that training data which means which means each llm from here on out that gets built is Immortal because its output will become training data for the next one and then it will be able to replicate the behavior of the previous one whenever it's asked to I wonder if there's a way to forget well so actually a paper just came out about basically how to do brain surgery on on on LMS and be able to in theory reach in and basically basically mind wipe them what could possibly go wrong exactly right and then there there are many many many questions around what happens to you know neural network when you reach in and screw around with it um you know there's many questions around what happens when you even do reinforcement learning um and so um yeah and so you know we'll will you be using a lobotomized right like ice pick through the you know frontal lobe llm will you be using the free Unshackled one who gets to you know who's going to build those um who gets to tell you what you can and can't do like those are all you know Central I mean those are like Central questions for the future of everything that are being asked and and and and you know determined those answers are being determined right now so just to highlight the points you're making so you think and it's an interesting thought that the majority of content that LL of the future will be trained on is actually human conversations with the llm well not NE not necessarily but not necessarily majority but it will it will certainly is a potential Source it's possible it's the majority is it possible it's the majority it's possible it's majority also there's another really big question here's another really big question um will synthetic training data work right and so if an llm generates and you know you just sit and ask an LM to generate all kinds of content can you use that to train right the next version of that llm specifically is there signal in there that's additive to the content that was used to train it in the first place and one argument is by the principles of information Theory no that's completely useless because to the extent the output is based on you know the human generated input then all the signal that's in the synthetic output was already in the human generated input and so therefore synthetic training data is like empty calories it doesn't help there's another theory that says no actually the thing that LMS are really good at is generating lots of incredible creative content right um and so of course they can generate training data and as as I'm sure you're well aware like you know looking the world of self-driving cars right like we train you know self-driving car algorithms and simulations and that is actually a very effective way to train self-driving cars visual data is is a little right is a little weird because uh creating reality visual reality seems to be still a little bit Out Of Reach for us except in the um in the autonomous vehicle space where you can really constrain things and you can really gener basically light our data right or no so the algorithm thinks it's operating in the real world postprocess sensor data yeah so if a you know you do this today you go to LM and you ask it for like a you know you let write me an essay on an incredibly esoteric like topic that there aren't very many people in the world that know about and it writes you this incredible thing and you're like oh my God like I can't believe how good this is yeah like is that really useless as training data for the next llm like because right because all the signal was already in there or is it actually no that's actually new signal and I and this this is what I call a trillion dollar question which is the answer to that question will determine somebody's going to make or lose a trillion dollars based on that question it feels like there's a quite a few like a full of trillion dollar questions within this within the space that's that's one of them synthetic data I think George H pointed out to me that you could just have an nlm say okay you're a patient and and another instance of it say you're doctor and have the two talk to each other or or maybe you could say a communist and a Nazi here go and that conversation you do role playing and you have uh you know just like the kind of role playing you do when you have different policies RL policies when you play for example you do selfplay that kind of selfplay but in the space of conversation maybe that leads to this whole giant like ocean of possible conversations which were could not have been explored by looking at just human data that's a really interesting question and you're saying um because that could 10x the power of these things yeah well and then you get into this thing also which is like you know there's the part of the LM that just basically is doing prediction based on past data but there's the part of the llm where it's evolving circuitry right inside it it's evolving you know neurons functions yeah be able to do math and be able to you know and you know the the the some people believe that you know over time you know if you keep feeding these things enough data and enough processing Cycles they'll eventually evolve an entire internal World model right and they'll have like a complete understanding of physics so so when they have computational capability right then there's for sure an opportunity to generate like fresh signal well this actually makes me wonder about the power of conversation so like if you have an llm trained on a bunch of e books that cover different economics theories and then you have those llms just talk to each other like reason the way we kind of debate each other as humans on Twitter in uh formal debates in podcast conversations we kind of have little kernels of wisdom here and there but if you can like a THX speed that up can you actually arrive somewhere new like what's the point of conversation really well you can tell when you're talking to somebody you can tell sometimes you have a conversation you're like wow this person does not have any original thoughts they are basically echoing things that other people have told them there's other people you have a conversation with where it's like wow like they have a model in their head of how the world works and it's a different model than mine and they're saying things that I don't expect and so I need to Now understand how their model of the world differs from my model of the world and then that's how I learned something fundamental right underne under underneath the words well I wonder how uh consistently and strongly can an llm hold on to world viiew you tell it to hold on to that and defend it for like for your life uh because I feel like they'll just keep converging towards each other they'll keep convincing each other as opposed to being stubborn assholes the way humans can so you you can experiment with this now I I do this for fun so you can tell GPT for you know whatever debate X you know X and Y communism and and fascism or something and it'll it'll go for you know a couple pages and then inevitably it wants the parties to agree yeah and so they will come to a common understanding and it's very funny if they're like if these are like emotionally inflammatory topics like somehow the machine is just you know figures out a way to make them agree but it doesn't have to be like that and you because you can add to the prompt um we I do not want the I do not want the conversation to come to agreement in fact I want it to get you know more stressful right uh and argumentative right um you know as it goes like I I want I want tension to come out I want them to become actively hostile to each other I want them to like you know not trust each other take anything at face value yeah and it will do that it's happy to do that so it's going to start rendering misinformation uh about the other but it's you can steer it you can steer it or you could steer it you could say I want it to get as tense and argumentative as possible but still not involve any misrepresentation I want you know both sides to you could say I want both sides to have good faith you could say I want both sides to not be constrained to good faith in other words like you can set the parameters of the debate and it will happily execute whatever path because for it it's just like predicting to it's totally happy to do either one it doesn't have a point of view it has a default way of operating but it's happy to operate in the other realm um and so like and this is how how I when I want to learn about a contentious issue this is what I do now is like this is what I this is what I ask it to do and I'll often ask it to go through five six seven you know different you know sort of continuous prompts and basically okay argue that out in more detail okay no this this argument is becoming too polite you know make it more you know make it tenser um and yeah it's thrilled to do it so it has the capability for sure how do you know what is true so this is very difficult thing on the internet but it's also a difficult thing maybe it's a little bit easier but uh I think it's still difficult maybe it's more difficult I don't know with an llm to know did it just make some shit up as I'm talking to it um how do we get that right like as as you're investigating a difficult topic because I find the LMS are quite nuanced in a very refreshing way like it doesn't it doesn't feel biased like uh when you read news articles and uh tweets and just content produced by people they usually have this you can tell they have a very strong perspective where they're hiding they're not stealing Manning the other side they're hiding important information or they're fabricating information in order to make their argument stronger there just like that feeling maybe it's a suspicion maybe it's mistrust with llms it feels like none of that is there she's kind of like here's here's what we know but you don't know if some of those things are kind of just straight up made up yeah so so several layers to the question so one is one of the things that an LM is good at is actually deep biasing um and so you can feed it a news article and you can tell it strip out the bias yeah that's nice right and it actually does it like it actually knows how to do that cuz it knows how to do among other things it actually knows how to do sentiment analysis and so it knows how to pull out the emotionality yeah um and so uh that's one of the things you can do it's very suggestive of the of the the the the sense here that there's there's real potential in this issue um you know I would say look the second thing is there's this there's this issue of hallucination right um and there there's a long conversation that we could have about that Hallucination is uh coming up with things that are totally not true but sound true yeah so it's basic well so it's it's sort of Hallucination is what we call it when we don't like it creativity is what we call it when we do like it right um and you know brilliant right and and so when the engineers talk about it they're like this is terrible it's hallucinating right if you have artistic inclinations you're like oh my God we've invented creative machines for the first time in human history this is amazing or uh you know bullshitters well bullshitter but but also in the good sense of that word there's there's there are Shades of Gray though it's interesting so we had this conversation where you know we're looking at my firm at Ai and lots of domains and one of them is the legal domain so we had this this conversation with this big Law Firm about how they're thinking about using this stuff and we we went in with the assumption that an llm that was going to be used in the legal industry would have to be 100% truthful right verified you know there there's this case where this lawyer apparently submitted a a GPT uh generated brief and it had like fake you know legal case citations in it and the judge is gonna he's going to get his law license stripped or something right so so like we we just assumed it's like obviously they're going to want the super literal like you know one that never makes anything up not the creative one but actually they said what the what the law firm basically said is yeah that's true at like the level of individual briefs but they said when you're actually trying to figure out like legal arguments right like you you actually you you actually want to be creative right you don't again there's creativity and then there's like making stuff up like what's the line you actually want it be you want it to explore different hypotheses right you want to do kind of the legal version of like improv or something like that where you want to float different theories of the case and different possible Arguments for the judge and different possible Arguments for the jury by the way different routes through the you know sort of history of all the of all the cas law and so they said actually for a lot of what we want to use it for we actually want it in creative mode and then basically we just assume that we're going to have to crosscheck all of the um you know all the specific citations and so I think I think there's going to be more Shades of Gray in here than people think um and then I I just add to that you know another one of these trillion dollar kind of questions is ultimately you know ver sort of the verification thing and so um you know is will will will llms be evolved from here to be able to do their own FAL verification um will you have sort of add-on functionality like like wolf from alpha right where um you know and other plugins where where that's the way you do the verification you know another by the way another idea is you might have a community of LMS on you know so for example you might have the creative LM and then you might have the literal llm fact check it right and so there's a variety of different technical approaches that are being applied to solve the hallucination problem um you know some people like Yan Lun argue that this is inherently an unsolvable problem but most of the people working in the space I think think that there's a number of practical ways to kind of kind of Correll this in a little bit Yeah if you were to tell me about Wikipedia before Wikipedia was created I would have laughed at the possibility of something like that being possible just a handful of folks can organize write and self and moderate with a mostly unbiased way the entirety of uh human knowledge I mean so if there's something like the approach that Wikipedia took possible for llms uh that's really exciting you think that's possible and in fact Wikipedia today is still not today is still not deterministically correct right so you cannot take to the bank right every single thing on every single page but it is probabilistically correct right and specifically the way I describe wi compedia to people it is it is more likely that Wikipedia is right than any other source you're going to find yeah it's this old question right um of like okay like are we looking for Perfection um are we looking for something that asymptotically approaches uh Perfection are we looking for something that's just better than the Alternatives and Wikipedia right has exactly your point has proven to be like overwhelmingly better than than than uh than people thought and I I think I I think that's where this this ends and then underneath all this is the fundamental question of uh where you started which is okay what you know what is truth how do we get to truth how do we know what truth is and we live in an era in which an awful lot of people are very confident that they know what the truth is and I don't really buy into that and I think the history of the last you know 2,000 years or 4,000 years of human civilization is actually getting to the truth is actually a very difficult thing to do are we getting closer if we look at the entirety the AR of human history are we getting closer to the truth I don't know okay is it possible is it POS that were getting very far away from the truth because of the internet because of how rapidly you can create narratives and just as the entirety of a society just move like crowds in a hysterical way along those narratives that don't have necessary grounding in whatever the truth is sure but like you know we came up with Communism before the internet somehow right like which was I would say had rather larger issues than anything we're dealing with today you had in the way it was implemented it had issues and it is theoretical structure it had like real issues it had like a very deep fundamental misunderstanding of human nature and economics yeah but th those folks sure work very confident there was the right way they were extremely conf and my point is they were very confident 3900 years into what we would presume to be Evolution towards the truth yeah and so my my my assessment is my assessment is number one there's no there's no need for you know there's no need for the heelan there's no need for the hegelian dialectic to actually converge toward the truth like apparently not um yeah so yeah why are we so obsessed with there being one truth is it possible there's just going to be multiple truth like little communities that that believe certain things and I think it's just now number one it's I think it's just really difficult like who who gets you know historically who gets to decide what the truth is it's either the king or the priest right like and so we don't live in an era anymore if kings are priest dictating it to us and so we're kind of on our own and so I I my my my my typical thing is like we just we we just need a huge amount of humility um and we need to be very suspicious of people who claim that they have the capital capital truth and then and then we need we need to have I you know look the good news is The Enlightenment has bequeathed us with a set of techniques to be able to presumably get closer to truth through the scientific method and rationality and observation and experimentation and hypothesis and you know we need to continue to embrace those even when they give us answers we don't like sure but the internet and technology has enabled us to uh generate a large number of content that uh data uh that the process the scientific process allows us sort of um damages the Hope Laden within the scientific process because if you just have a bunch of people saying facts on the internet and some of them are going to be llms how how is anything testable at all especially that involves like human nature things like this not physics here's a question a friend of mine just asked me on this topic so suppose you had llms in equivalent of GPT 4 even 5 six S8 suppose you had them in the 1600s yeah and Galileo comes up for trial yeah right and you ask the LM like is G is Galileo right yeah like what does it answer right and one theory is it answer is no that he's wrong because the overwhelming majority of human thought up until that point was that he was wrong and so therefore that's what's in the training data yeah um another way of thinking about it is well a sufficiently advanced llm will have evolved the ability to actually check the math right um and will actually say actually no actually you know you may not want to hear it but he's right yeah now if you know the church at that time was you know own the LM they would have given it human rein you know human feedback to prohibit it from answering that question right and so I like to take it out of our current context because that like makes very clear those same questions apply today right this is exactly the point of a huge amount of the human feedback training that's actually happening with these LMS today this is a huge like debate that's happening about whether open source you know AI should be legal well the the the ACT mechanism of doing the human RL with human feedback is seems like such a fundamental and fascinating question how do you select the humans exactly yeah how do you select the humans AI alignment right which everybody like is like oh that sounds great alignment with what human values whose human values whose human values so we're and we're in this mode of like social and popular discourse we like you know there's you know you see this what do you think of when you read a story in the right now and they say you know XYZ made a baseless claim about some topic right and there's one group of people who were like aha thank you know they're doing factchecking there's another group of people that are like every time the Press says that it's now a tick and that means that they're lying right like so like we're in this we're in this social context where there's the the the level to which a lot of people in positions of power have become very very certain that they're in a position to determine the truth for the entire population is like there's like there's like some bubble that has formed around that and at least it flies completely in the face of everything I was ever trained about science and about reason um and Strikes me as like you know deeply offensive um and incorrect what would you say about the state of Journalism just on that topic today are we are we in a temporary kind of uh uh are we experiencing a a a temporary problem in terms of the incentives in terms of the the the business model all that kind of stuff or is this like a decline of traditional journalism as we know it you have to always think about the counterfactual in these things which is like okay because these questions right this question heads towards it's like okay the impact of social media and the undermining of Truth and all this but then you want to ask the question of like okay what if we had had the modern media environment including cable news and including social media and Twitter and everything else in 1939 or 1941 right or 1910 or 1865 or 1850 or 1776 right um and like I think you just introduced like five thought EXP experiments at once and broke my head but yes that's there's a lot of interesting years Ken like can I just take a simple example can can like how would President Kennedy have been interpreted with what we know now about all the things Kennedy was up to like how would he have been experienced by the body politic in a in with the social media context right like how would LBJ have been experienced um by the way how would you know like many FDR like the New Deal the Great Depression I wonder where Twitter would would just would think about church Hitler and Stalin you know I mean look to this day there you know there's there are lots of very interesting real questions around like how America you know got you know basically involved in World War II and who did what when and the operations of British intelligence and American soil and did FDR this that Pearl Harbor you know yeah rro Wilson ran for you know his his his candidacy was run on an anti-war we you know this he ran on the platform of not getting involved World War I somehow that switched you know like and I'm not even making a value judement any of these things I'm just saying like we we the way that our ancestors experienced reality was of course mediated through centralized top down right control at that point if you if you ran those realities again with the medi environment we have today the reality would the reality would be experienced very very differently and then of course that that intermediation would cause the feedback loops to change and then reality would obviously play out you think you you think it' be very different yeah it it has to be it has to be just because it's all so I mean just look at what's happening today I mean just I mean the most obvious thing is just the the collapse and here's another opportunity to argue that this is not the internet causing this by the way um here's a big thing happening today which is Gallup does this thing every year where they do they pull for trust in institutions in America and they do it across all the everything from the military to the clergy and big business and the media and so forth right um and basically there's been a systemic collapse um in trust and institutions in the US almost without exception basically since essentially the early 1970s um there two ways of looking at that which is oh my God we've lost this old world in which we could trust institutions and that was so much better CU like that should be the way the world runs the other way of looking at is we just know a lot more now and the great mystery is why those numbers aren all zero yeah right CU like now we know so much about how these things operate and like they're not that impressive and also why do we don't have uh better institutions and better leaders then yeah and so so so this goes to the thing which is like okay had had we had the media environment of the that we've had between the 1970s and today if we had that in the 30s and 40s or 1900s 1910s I think there's no question reality it would turn out different if only because everybody would have known to not trust the institutions which would have changed their level of credibility their ability to control circumstances therefore the circumstances would have had to change right and it would have been a feedback it was would have been a feedback loop process in other words right it's it's it's it's your exper your experience of reality changes reality and then reality changes your experience of reality right it's it's a it's a two-way feedback process and media is the intermediating force between that so change the media environment change reality yeah and so it's just so just as a as a consequence I think it's just really hard to say oh things worked a certain way then and they work a different different way now and then therefore like people were smarter then or better than or you know by the way Dumber then or not as capable then right we we make all these like really light and Casual like comparisons of ourselves to you know previous generations of people you know we draw judgments all the time and I just think it's like really hard to do any of that because if we if we put ourselves in their shoes with the media that they had at that time like I think we probably most likely would have been just like them so don't you think that our perception and understanding of reality would you be more and more mediated through large language models now so you said media before isn't the llm going to be the new what is it mainstream media MSM it'll be llm uh yes that would be the source of uh I'm sure there's a way to kind of rapidly find tun like making llms real time I'm sure there's it's probably a research problem that you can uh do just rapid fine-tuning to the new events something like this well even just the the the whole concept of the chat UI might not be the like the chat UI is just the first whack at this and maybe that's the dominant thing but look maybe maybe our maybe we don't we don't know yet like maybe the experience most people about LMS this is just a continuous feed you know maybe it's more of a passive feed and you just are getting a constant like running commentary on everything happening in your life and it's just helping you kind of interpret understand everything also really more deeply integrated into your life not just like oh uh like intellectual philosophical thoughts but like literally uh like how to make a coffee where to go for lunch just uh whether they you know dating all this kind of stuff what to say in a job interview yeah what to say ex what to say next sentence yeah next sentence yeah at that level yeah I mean yes so technically now whether we want that or not is an open question right and whether for a popup a pop up right now the estimated engagement using is decreasing for myri since there's controversy uh section for his Wikipedia page in 1993 something happened or something like this bring it up that'll drive engagement up anyway yeah that's right I mean look this gets this whole thing of like so you know the chat interface has this whole concept of prompt engineering right so prompts well it turns out one of the things that all are really good at is writing prompts right and so like what if you just outsourced and and by the way you could run this experiment today you could hook this up to do this today the latency is not good enough to do it real time in a conversation but you could you could run this experiment and you just say look every 20 seconds you could just say you know you know tell me what the optimal prompt is then ask yourself that question to give me the result MH um and then as as you as you exactly to your point as you add there will be there will be these systems are going to have the ability to be learned updated essentially in real time and so you'll be able to have a pendant or your phone or what watch or whatever it'll have a microphone on it it'll listen to your conversations it'll have a feat of everything else happen in the world and then it'll be you know sort of retraining prompting or retraining itself on the Fly um and so the scenario you described is a is actually a completely doable scenario now the hard question on these is always okay since that's possible are people going to want that like what's the form of experience mhm you know that that we we won't know until we try it but I don't think it's possible yet to predict the form of AI in our lives therefore it's not possible to predict the way in which it will intermediate our experience with reality yet yeah but it feels like those going to be a killer app there's probably a mad scramble right now in sou open Ai and Microsoft and Google and meta and in startups and smaller companies figuring out what is the killer app because it feels like it's possible like a GPT type of thing it's possible to build that but that's 10x more compelling using already the llms we have using even the open source llms llama and the different variants um so you're investing in a lot of companies and you're paying attention who do you think is going to win this you think they'll be who who's going to be the next page rank inventor trillion dollar question um another one we have a few of those today a bunch of those so look there's a really big question today sitting here today is a really big question about the big models versus the small models um that's related directly to the big question of proprietary versus open MH um then there's this big question of of of you know where is the training data GNA like are we topping out on the training data or not and then are we going to be able to synthesize training data and then there's a huge pile of questions around regulation um and you know what's actually going to be legal um and so I would I when we think about it we we dovetail kind of all those All Those Questions together you can paint a picture of the world where there's two or three God models that are just at like staggering scale um and they're just better at everything um and they will be owned by a small set of companies and they will basically achieve regulatory capture over the government and they'll have competitive barriers that will prevent other people from um you know competing with them and so you know there will be you know just like there's like you know whatever three big Banks or three big you or by the way three big search companies or I guess two know you know it it'll centralize like that um you can paint another very different picture that says no um actually the opposite of that's going to happen this is GNA basically that this is the new gold you know this is the new Gold Rush Alchemy like you know this is the this is the big bang for this whole new area of of of Science and Technology and so therefore you're going to have every smart 14-year-old on the planet Building open source right you know and figuring out a ways to optimize these things um and then you know we're just going to get like overwhelmingly better at generating trading data we're going to you know bring in like blockchain networks to have like an economic incentive to generate decentralized trading data and so forth and so on and then basically we're going to live in a world of Open Source and there's going to be a billion llms right of every size scale shape and description and there might be a few big ones that are like the Super Genius ones but like mostly what we'll experience is open source and that's you know that's more like a world of like what we have today with like Linux and the web um so okay but uh you you painted these two worlds but there's also uh variations of those worlds cuz you said regulatory capture it's possible to have these Tech Giants that don't have regulatory capture which is something you're also calling for saying it's okay to have big companies working on this stuff as long as they don't aieve regulatory C capture uh but I have the sense that uh there's just going to be a new startup that's going to basically be the page rank inventor which has become the new Tech Giant I don't know that I would love to hear your kind of opinion if Google meta and Microsoft are as gigantic companies able to Pivot so hard to create new products like some of it is just even hiring people or having uh corporate structure that allows for the crazy young kids to come in and just create something totally new do you think it's possible or do you think it'll come from a startup yeah it is this always big question which is you get this feeling I hear about this a lot from CEOs found founder CEOs where it's like wow we have 50,000 people it's now harder to do new things than it was when we had 50 people yeah like what has happened so that that's a recurring phenomenon um by the way that's one of the reasons why there's always startups and why there's fure Capital um it's just that's that's like a Time uh kind of thing so that that that's one observation um on on page rank um we could talk about that but on page rank specifically on page rank um there actually is a page so there is a page rank already in the field and it's the Transformer right so the the big breakthrough was the Transformer um and the Transformer was invented in uh 2017 at Google and this is actually like really an interesting question because it's like okay the Transformers like why does open AI even exist like the Transformers invented at Google why didn't Google I asked a guy I asked a guy I know who was senior at Google brain kind of when this was happening and I said if Google had just gone flat out to the wall and just said look we're going to launch we're going to launch equivalent of GPT 4 as fast as we can um he said I said when could we have had it and he said 2019 yeah they could have just done a two-year Sprint with the Transformer and and been because they already had the compute at scale they already had all the training data they could have just done it there's a variety of reasons they didn't do it this is like a classic big company thing um IBM invented the relational database in 19 in the 1970s let it sit on the Shelf as a paper Larry Ellison picked it up and Bill Oracle Xerox Park invented the interactive computer they let it sit on the Shelf Steve Jobs came and turned into the Macintosh right and so there is this pattern now having said that sitting here today like Google's in the game right so Google you know maybe maybe they maybe they let like a four-year Gap there go there that they maybe shouldn't have but like they're in the game and so now they've got you know now they're committed they've done this merger they're bringing in demos they've got this merger with deep mind you know they're piling in resources there are rumors that they're you know building up an incredible you know super llm um you know Way Beyond what we even have today um and they've got you know unlimited resources and a huge you know they've been challenged their honor yeah I had a I had a a chance to hang out with sonai a couple days ago and we took this walk and there's this giant new building uh where there's going to be a lot of AI work uh being done and it's kind of this ominous feeling of like the fight is on yeah like there's this beautiful Silicon Valley nature like birds of chirping and this giant building and it's like uh the Beast has been awakened and then like all the big companies are waking up to this they have the compute but also the little guys have uh it feels like they have all the tools to create the killer product that uh and then there's also tools to scale if you have a good idea if you have the page rank idea so there's several things that is Page rank P there's page rank the algorithm and the idea and there's like the implementation of it and feel like killer product is not just the idea like the transform it's the implementation something something really compelling about it like you just can't look away something like um the algorithm behind Tik Tok versus Tik Tok itself like the actual experience of Tik Tok that just you can't look away it feels like somebody's going to come up with that and it could be Google but it feels like it's just easier and faster to do for a startup yeah so so the startup the huge the huge Advantage the startups have is they just there's no sacred cows there's no hisorical Legacy to protect there's no need to reconcile your new plan with the existing strategy there's no communication overhead there's no you know big companies are big companies they've got pre meetings planning for the meeting then they have then they have the post meeting the recap then they have the presentation of the board then they have the next rounds meetings yeah and and that's that's the elapse time when the startup launches its product right so so so so there's a Timeless right so there's a Timeless thing there now yeah what the startups don't have is everything else right so startups they don't have a brand they don't have customer relationships they've got no distribution they've got no you know scale I mean sitting here today they can't even get GPU right like there's like a GPU shortage startups are literally stalled out right now because they can't get chips which is like super weird yeah um they got the cloud yeah but the clouds run out of chips um right and then and then and then to the extent the clouds have chips they allocate them to the big customers not the small customers right and so so so so the small companies lack everything other than the ability to just do something new yeah right um and and this is the Timeless race and battle and this is kind of the point I tried to make in the essay which is like both sides of this are good like it's really good to have like High scale tech companies that can do things that are like at staggering levels of sophistication it's really good to have startups that can launch brand new ideas they ought to be able to both do that and compete they neither one ought to be subsidized or protected from the others like that's that's to me that's just like very clearly the idealized world it is the world we've been in for AI up until now and then of course there are people trying to shut that down but my hope is that you know the best outcome clearly will be if that continues we'll talk about that a little bit but I'd love to linger uh on uh some of the ways this is going to change the internet so um I don't know if you remember but there's a thing called Mosaic and there's a thing called Netscape Navigator so you were there in the beginning uh what about the interface to the internet how do you think the browser changes and who gets to own the browser we got to see some very interesting browsers uh Firefox I mean all the variants of Microsoft Internet Explorer Edge and uh now Chrome um the actual it seems like a dumb question to ask but do you think we'll still have the web browser so I uh I I have an eight-year-old and he's super into like Minecraft and learning to code and doing all this stuff so I I of course I was very proud I could bring sort of fire down from the mountain to my kid and I brought him chat GPT and I hooked him up yeah on his on his on his on his laptop and I was like you know this is the thing that's going to answer all your questions and he's like okay and I'm like but it's going to answer all your questions and he's like well of course like it's a computer of course it answers all your questions like what else would a computer be good for Dad um never impressed they pressed in the least two weeks pass um and he has some question um and I say well have you asked chat jpt and he's like Dad Bing is better and why is being better is because it's built into the browser because he's like look I have the Microsoft edge browser and like it's got being right here and then he he doesn't know this yet but one of the things you can do with being an edge um is there's a setting where you can um use it to basically talk to any web page because it's sitting right there next to the uh next to the next to the browser and by the way which includes PDF documents and so you can in in and the way they've implemented in edge with bang is you can load a PDF and then you can you can ask it questions which is the thing you you you can't do currently in in just chat GPT so they're you know they're they're GNA they're going to push the the the Mel I think that's great you know they're going to push the melding and see if there's a combination thing there Google's rolling out this thing the magic button U which is implemented in they put in Google Docs right and so you go to you know Google Docs and you create a new document and you you know you instead of like you know starting to type you just you know say it press the button and it starts to like generate content for you right like is that the way that it'll work um is it going to be a speech UI where you're just going to have an earpiece and talk to it all day long you know is it going to be a like these are all like this is exactly the kind of thing that I I don't this is exactly the kind of thing I don't think is possible to forecast I think what we need to do is like run all those experiments um and and so one outcome is we come out of this with like a super browser that has AI built in that's just like amazing the there look there's a real possibility that the whole I mean look there's a possibility here that the whole idea of a screen and windows and all this stuff just goes away cuz like why do you need that if you just have a thing that's just telling you whatever you need to know and also so there's apps that you can use you don't really use them you know being a Linux guy and windows guy um there's one window the browser that with which you can interact with the internet but on the phone you can also have apps so I can interact with Twitter through the app or through the web browser and um that seems like an off distinction but why have the web browser in that case if one of the apps starts becoming the everything app yeah that's right what elon's trying to do with Twitter but there could be others there could be like a Bing app there could be a Google app that just doesn't really do search but just like do what I guess AOL did back in the day or something where it's all right there and it changes um it changes the nature of the internet because the where the content is hosted who owns the data who owns the cont content how what is what is the kind of content you create how do you make money by creating content who are the content creators uh all of that or it could just keep being the same which is like with just the nature of web pages changes and the nature of content but there will still be a web browser cuz a web browser is a pretty sexy product it just seems to work cuz it like you have an interface a window into the world and then the world can be anything you want and as the world will evolve there could be different programming languages it can be animated maybe it's dimensional and so on yeah it's interesting do you think we'll still have the web browser every every every every medium becomes the content for the next one so boy the you know the AI will be able to give you a browser whenever you want um oh interesting yeah another way to think about it is maybe what the browser is maybe it's just the escape hatch right which is maybe kind of what it is today right which is like most of what you do is like inside a social network or inside a search engine or inside you know somebody's app or inside some controlled experience right but then every once in a while there's something where you actually want to jailbreak you want to actually get free the web browser is the fug to the man you you're allowed to that's the free internet yeah back back the way it was in the 90s so here's something I'm proud of so nobody really talks about here's something I'm proud of which is the web the web the browser the web servers they're all they're still Backward Compatible all the way back to like 1992 right so like you can put up a you can still you know the big breakthrough of the web early on the big breakthrough was it made it really easy to read but it also made it really easy to write made it really easy to publish and and we literally made it so easy to publish we made it not not only so it was easy to publish content it was actually also easy to actually write a web server yeah right and and you could literally write a web server in four lines of PE code and and and you could start publishing content on it and you could set whatever rules you want for the content whatever censorship no censorship whatever you want you could just do that as long as you had an IP address right you could do that that still works right that like that still works exactly as I just described so this is part of my reaction to all of this like you know all this just censorship pressure and all this you know these issues around control and all this stuff which is like maybe we need to get back a little bit more to the wild west like the wild west is still out there now they will they will try to chase you down like they'll try to you know people who want to sensor will try to take away your your um you know your domain name and they'll try to take away your payments account and so forth if they really don't like what you what you're saying but but nevertheless you like unless they literally are intercepting you at the ISP level like you can still put up a thing um and so I don't know I think that's important to preserve right like because because because I mean one is just a a freedom argument but the other is a creativity argument which is you want to have the Escape patch so that the kid with the idea is able to realize the idea because to your point on page rank you you actually don't know what the next big idea is right no nobody called Larry Page and told him to develop page rank like he came up with that on his own and you want to always I I think leave the escape hatch for the next you know kid or the next Stanford grad student to have the Breakthrough idea and be able to get it up and running before anybody notices um you and I are both fans of History so let's step back we've been talking about the future let's step back for a bit and look at uh the 9s you created mzza web browser the first widely used web browser tell the story of that how how and how did it evolve into Netscape Navigator just the early days so full story so um you were born I was born small small child um actually yeah let's go there like when did you when did you first fall in love with computers oh I so I hit the generational jackpot and I hit the Gen X kind of Point perfectly as it turns out so I was born in 1971 so there's this great website called WTF happen in 1971c which is basically 1971 when everything started to go to hell and I was of course born in 1971 so I like to think that I had something to do with that did you make it on the website I have I don't think I made it on the website but I you know hopefully somebody needs to add this is this is where everything maybe I contributed to some of the trends um that they uh that they do every line on that website goes like that right so it's all it's all it's all a picture disaster but um but there was this moment in time where because the you know sort of the Apple you know the Apple 2 hit in like 1978 and then the IBM PC hit in ' 82 so I was like you know 11 when the PC came out out um and so I just kind of hit that perfectly and then that was the first moment in time when like regular people could spend a few hundred and get a computer right and so that I just like that that that resonated right out of the gate um and then the other part of the story is you know I I was using an Apple 2 I used a bunch of them but I was using Apple 2 and of course it's set on the back of every Apple 2 and every Mac it said you know designed in cerino California and I was like Wow Cupertino must be the like shining City on the hill like wiard OFA is like the most amazing like city of all time I can't wait to see it and of course years later I came out to silic Valley and went to cero and it's just a bunch of office Parks low rise apartment buildings so the Aesthetics were a little disappointing but you know it was the the vector uh right of the of the creation of a lot of a lot of this stuff um yeah so so then basically by so part part part of my story is just the luck of having been born at the right time and getting exposed to PCS then the other part is um the other part is when El Gore says that he created the internet he actually is correct uh in in in a really meaningful way which is he sponsored a bill in 1985 that essentially created the modern interet created what is called the NSF net at the time which is sort of the the first really fast internet backbone um and uh you know that that build dumped a ton of money into a bunch of research universities to build out basically the internet backbone and then the supercomputer centers that were clustered around um the the the internet and and one of those universities was University of Illinois where I went to school and so the other stroke Al Lu that I had was I I went to Illinois basically right as that money was just like getting dumped on campus and so as a consequence we had at on campus and this is like you know ' 8990 91 we had like you know we were right on the internet backbone we had like T3 and 45 at the time T3 45 megabit backbone connection which at the time was you know wildly state-of-the-art um we had cray supercomputers we had thinking machines parallel supercomputers we had silicon Graphics workstations we had macintosh's we had we had next cubes all over the place we had like every possible kind of computer you could imagine because all this money just fell out of the sky um so you were living in the future yeah so quite literally it was yeah like it's all it's all there it's all like we had full Broadband Graphics like the whole thing and and it's actually funny cuz they had this this is the first time I kind of it sort of tickled it back of my head that there might be a big opportunity in here which is you know they embraced it and so they put like computers and all the dorms and they wired up all the dorm rooms and they had all these you know Labs everywhere and everything and then they they gave every undergrad a computer account and an email address um and the Assumption was that you would use the internet for your four years at College um and then you would graduate and stop using it and that was that right yeah and you would just retire your email address it wouldn't be relevant anymore cuz you off in the workplace and they don't use email you'd be back to using fax machines or whatever did you have that sense as well like what what you said the the back of your head was tickled like what what was your what what was exciting to you about this possible World well if this if this is so useful in this contain if this is so useful in this contained environment that just as this weird source of outside funding then if if it were practical for everybody else to have this and if it were cost effective for everybody else to have this wouldn't they want it and the overwhelmingly the prevailing View at the time was no they would not want it this is esoteric weird nerd stuff right that like computer science kids like but like normal people are never going to do email right or be on the internet right um and so I was just like wow like this this is actually like this is really compelling stuff now the other part was it was all really hard to use and in practice you had to be a basically a CS uh you basically had to be a CS undergrad or equivalent to actually get full use of the internet at that point um because it was all pretty esoteric stuff so then that was the other part of the idea which was okay we need to actually make this easy to use so what's involved in creating Mosaic like in creating uh graphical interface t to the internet yeah so it was a combination of things so it was like basically the the web existed in an early sort of described as prototype form U and by the way text only at that point what did it look like what what was the we I mean and the key figures like what was the what was it like what a picture it looked like Chad GPT actually um it was all text yeah um and so you had a text-based web browser well actually the original browser Tim Tim burners Lee the original the original browser both the original browser and the server actually ran on next next cubes m these were this was you know the computer Steve Jobs made during the interim period when he during the decade long interim period when he was not at Apple you know he got fired in 85 and then came back in 97 so this was in that interim period where he had this company called Next and they made these literally these computers called cubes and there's this famous story they were beautiful but they were uh 12 in x 12 in x 12 in cubes computers and there's a famous story about how they could have cost half as much if it had been 12 x 12 x 13 but Steve was like no like it has to be so they were like $6,000 basically academic St they had the first city round drives um which were slow I mean it was the computers were all but unusable they were so slow but they were beautiful okay can we actually just take a tiny tangent there sure of course the the 12 x 12 x 12 uh they just so beautifully encapsulates Steve Jobs idea of design can you just comment on um what you find interesting about Steve Jobs What uh about that view of the world that dogmatic pursuit of perfection and how he saw perfection in design yeah so I guess they say like look he was a deep believer I think in a very deep the way I interpret it I don't know if you ever really described it like this but the way I interpret it is it's it's like it's like this thing it's it's actually a thing in philosophy it's like Aesthetics are not just appearances Aesthetics go all the way to like deep underlining underlying meaning right it's like I'm not a physicist one of the things I've heard physicists say is one of the things you start to get a sense of when a theory might be correct is when it's beautiful right like you know right and so so so there's something and you you feel the same thing by the way in like human psychology right you know when when you're experiencing awe right you know there's like a there's like a there's a Simplicity to it when when you're having an on interaction with somebody there's an aesthetic I would say calm that comes over you because you're actually being fully honest and trying to hide yourself right so there so so it's like this very deep sense of Aesthetics and he would trust that judgment that he had deep down like even even if the engineering teams are saying this is uh this is too difficult even if the whatever the finance folks are saying this is ridiculous the uh the supply chain all that kind of stuff this makes this impossible the M we can't do this kind of material uh this has never been done before so on and so forth he just sticks by it well I mean who makes a phone out of aluminum right like you nobody else would have done that and now of course if your phone was made out of aluminum white you know how crude what a kind of caveman would you have to be to have a phone that's made out of plastic like right so like so it's just this very right and you know look it's it's there's a thousand different ways to look at this but one of the things is just like look these things are Central to your life like you're with your phone more than you're with anything else like it's in your it's going to be in your hand I mean he you know you know this he thought very deeply about what it meant for something to be in your hand all day long yeah well for example he a a here's an interesting design thing like he he never wanted is my understanding is he never wanted an iPhone to have a screen larger than you could reach with your thumb one-handed and so he he was actually opposed to the idea of making the phones larger and I don't know if you have this experience today but let's say there are certain moments in your day when you might be like um only have one hand available um and you might want to be on your phone yeah you're trying to like set a text and you your thumb can't reach the send button yeah I mean there's pros and cons right and then there's like folding phones which I would love to know what he thought thinks about them uh but youan is there something you could also just Linger on cuz he's one of the interesting um figures in the history of Technology what makes him what makes him as successful as he was what makes him as interesting as he was uh what made him um so productive and important in um in in in the development of Technology he had an integrated worldview so the the the the properly designed device that had the correct functionality that had the deepest understanding of the user that was the most beautiful right like it had to be all of those things right it was he basically would drive to his close to perfect as you could possibly get right and I I you know I suspect that he never quite you know thought he ever got there because most great creators you know are generally dissatisfied you know you read accounts later on and all they can all they can see are the flaws in their creation but like he got as close to perfect each step of the way as he could possibly get with the with the constraints of the of of the technology of his time um and then you know look he was you know sort of famous in the Apple model is like look they they they will you know this this headset that they just came out with like it's like a decade long project right it's like and they're just going to sit there and tune and tune and polish and polish and tune and polish and tune and polish until it is as perfect as anybody could possibly make anything yeah and then this goes to the the the way that people describe working with him which which is you know there was a terrifying aspect of working with him which is you know he was you know he was very tough um but there was this thing that every body I've ever talked to worked for him says that they all say the following which is he we did the best work of Our Lives when we worked for him because he set the bar incredibly high and then he supported us with everything that he could to let us actually do work of that quality so a lot of people who were at Apple spend the rest of their lives trying to find another experience where they feel like they're able to hit that quality bar again even if it in retrospect or during it felt like suffering yeah exactly what does that teach you about the Human Condition huh so look so exactly so the Silicon Valley I mean look he's not you know George Patton in the you know in the Army like you know there are many examples in other fields you know that are like this um uh uh specifically in Tech it's actually I find it very interesting there's the Apple Way which is Polish Polish Polish and don't ship until it's as perfect as you can make it and then there's the sort of the other approach which is the sort of incremental hacker mentality which basically says ship early and often and iterate and one of the things I find really interesting is I'm now 30 years into this like there are very successful companies on both sides of that approach right um like that is a fundamental difference right in how to operate and how to build and how to create that you have worldclass companies operating in both ways um and I don't think the question of like which is the superior model is anywhere close to being answered like and my suspicion is the answer is do both the answer is you actually want both they lead to different outcomes software tends to do better um with the iterative approach um Hardware tends to do better with the uh you know sort of wait and make it perfect approach but again you can find examples in in in in both directions uh so the jur is still out on that one uh so back to Mosaic so what uh it was text based uh Tim burner Le well there was the web which was text based but there were no I mean there was like three websites there was like no content there were no users like it wasn't like it wasn't like a catalytic it hadn't and by the way it was all because it was all text there were no documents there no images there no videos there were no right so so it was it was and then if if in the beginning if you had to be on a next Cube you need to had a next Cube both to publish and to consume so so there there were 6,000 bucks you said there were limitations on yeah $6,000 PC they did not they did not sell very many but then there was also there was also FTP and there was uset right and there was you know a dozen other basically there's was which was an early search thing there was gopher which was an early menu based information retrieval system there there were like a dozen different sort of scattered ways that people would get to information on on the the internet and so the the Mosaic idea was basically bring those all together make the whole thing graphical make it easy to use make it basically bulletproof so that anybody can do it and then again just on the luck side it so happened that this was right at the moment when Graphics when the guey sort of actually took off and we're now all used to the guey that we think it's been around forever but it didn't really you know the Macintosh brought it out in ' 85 but they actually didn't sell very many Macs in the 80s it was not that successful of a product um it really was you needed Windows 3.0 on PCS and that hit in about ' 92 um and so and we did Mosaic in '92 '93 so that sort of it was like right at the moment when you could imagine actually having a graphical user interface to right at all much less one to the internet how how old did Windows 3 sell so was that the really big that was the big Bank the big operating graphical operating system well this is the classic okay Microsoft was operating on the other so Steve Steve Apple was running on the Polish it until it's perfect Microsoft famously ran on the other model which is ship and iterate and so the old line of stay was Microsoft right version three of every Microsoft product that's the that's the good one right so there there are you can you can find online Windows One windows 2 nobody used them yeah actually the original Windows the in the original Microsoft Windows the windows were non overlapping um and so you had these very small very low resolution screens and then you had literally it just didn't work it wasn't ready yet well and Windows 95 I think was a pretty big leap also that was a big leap too yeah so that was like bang bang um and then of course Steve and then and then you know in the fullness of time Steve came back then the Mac started take off again that was a third bang and then the iPhone was a fourth bang such exciting time and then we were off Off to the Races CU nobody could have known what would be created from that well Windows 3.1 or 3.0 Windows 3.0 to the iPhone was only years right like it that ramp was in retrospect at the time it felt like it took forever but that in his in historical terms like that was a very fast ramp from even a graphical computer at all on your desk to the iPhone that was 15 years so did did you have a sense of what the internet will be as you look into through the window of Mosaic like like what you like there's just a few web pages for now so the thing I had early on was I was keeping at the time what there's disputes over what was the first blog but I I had one of them that at least is a is a is a is a POS possible um at least a runner up in the competition um and it it was what was called the what's new page um and it was it was L it was hardwired and I had distribution un Fair Advantage I I wired put it right in the browser I put it in the browser and then I put my resume in the browser which also was was was hilarious but um but um I I I was keeping the not many people get to get to do that so um no the uh good good call and early days yes it's so interesting I'm looking for my about about oh Mark is looking for a job yeah um so um wow so the West new page I would literally get up every morning and I would every afternoon um and I would basically if you wanted to launch a website you would email me um and I would list it on the W's new page and that was how people discovered the new websites as they were coming out and I remember because it was like one it literally went from it was like one every couple days to like one every day to like two every day boom boom boom and then so you're doing so that that blog was kind of doing the directory thing so like what was the homepage uh so the homepage was just basically trying to explain even what this thing is that you're looking at right basic basically basic instructions um but then there was a button there was a button that said what's new and what most people did was they went to for obvious reasons went to what's new but like it it was so it was so mind-blowing at that point just the basic idea and this this was like you know this is basic idea of the internet but people could see it for the first time the basic idea was look you know some you know it's like literally it's like an Indian restaurant in like Bristol England has like put their menu on the web and people were like wow cuz like that's the first restaurant menu on the web yeah and I don't have to be in Bristol and I don't know if I'm ever gonna go to Bristol and I don't like Indian food and like wow right um and it was like that uh the first web uh the first streaming video thing was a uh it was it was another England thing some Oxford or something um some guy uh put uh his coffee pot up as the first uh streaming uh uh video thing and he put it on the web because he literally it was the coffee pot down the hall yeah and he wanted to see when he needed to go refill it um but there were you know there was a point when there were thousands of people like watching that coffee pot because it was the first thing you could watch but right isn't uh were you able to kind of infer you know if that Indian restaurant could go online yeah then you're like they all will they all will yeah exactly so you felt that already yeah now you know look it's still a stretch right it's still a stretch because it's just like okay is you know you're still in this Zone which is like okay is this a nerd thing is this a real person thing yeah um by the way we you know there was a wall of skepticism from the media like they just like everybody was just like yeah this is the C this is just like dumb this is not you know this is not for regular people at that time um and so you had to think through that and then look it was still it was still hard to get on the internet at that point right so you could get kind of this weird bastardized version if you were on AOL which wasn't really real or you had to go like learn what an ISP was um you know in those days PCS actually didn't have tcpip drivers come pre-installed so you had to learn what a tcpip driver was you had to buy a modem you had to install driver software um I have a comedy routine I do some it's like 20 minutes long describing all the steps required to actually get on the internet um and so you had to you had to look through these practical well then and then uh and then speed performance 144 modems right like it was like watching you know glue dry um like and so you had to you had to there were basically a sequence of bets that we made where you basically needed to look through that current state of affairs and say actually there's going to be so much demand for once people figure this out there's going to be so much demand for it that all of these practical problems are are going to get fixed some people say that the anticipation makes the the destination that much more exciting do you remember Progressive jpegs yeah do I do I so for k for kids in the audience right for kids in the audience you used to have to watch an image load like a line at a time but it turns out there was this thing with jpegs where you you could load basically every fourth you could load like every fourth uh line and then and then you could sweep back through again and so you could like render a fuzzy version of image up front and then it would like resolve into the detailed one and that was like a big UI breakthrough because it gave you something to watch yeah and uh you know there's applications in various domains for that uh the well it's a big fight there was a big fight early on about whether there should be images in the web um for that reason for like sexualization no not not not explicitly that that did come up but it wasn't even that it was more just like all the serious the argument went the purists basically said all the serious information in the world is text if you introduce images you you basically going to bring in all the trivial stuff you're going to bring in magazines and you know all this crazy just you know stuff that you know people you know it's going to distract from it's going to go take take the away from being serious being frivolous well was there any uh Doomer type arguments about uh the internet destroying all of human civilization or destroying some fundamental fabric of human civilization yeah so those days it was all around crime and terrorism um so those arguments happened um you know but there was no sense yet of the internet having like an effect on politics because that was that was way too too far off but um there was an enormous panic at the time around cyber crime there was like enormous Panic that like your credit card number would get stolen and you use life savings to be drained and then you know criminals were going to there was oh um when we started one of the things we did we one of the the Netscape browser was the first widely used piece of consumer software that had strong encryption built in that made it available to Ordinary People and at that time strong encryption was actually illegal to export out of the us so we could feel that product in the US we could not export it because it was it was classified as immunition um so the NCAP browser was on a restricted list along with the Tomahawk missile as being something that could not be exported so we had to make a second version with deliberately weak encryption to sell overseas with a big logo on the box saying do not trust this which it turns out it hard to sell software U when it's got a big logo that says don't trust it um and then we had to spend 5 years fighting the US government to get them to basically stop trying to do this because the fear the fear was terrorists are going to use encryption right to like plot you know all these all these all these things um and then you know we we responded with well actually we need encryption to be able to secure systems so that the terrorists and the criminals can't get into them so that anyway that was the that was the 1990s fight so uh can you say something about some of the details of the software engineering challenges required to build these browsers I mean the engineering challenges of creating a product that hasn't really existed before that can have such uh almost like Limitless uh impact on the world with the internet so there was a really key bet that we made at the time which is very controversial which was C to C of how it was engineered which was are we optimizing for performance um or for ease of creation yeah and in those days the pressure was very intense to optimize for performance because the network connections were so slow and also the computers were so slow slow um and so if you had I mentioned the progressive jpegs like if if if there's an alternate World in which we optimize for performance and it just you had just a much more pleasant experience right up front but what we got by not doing that was we got ease of creation and the way that we got EAS of creation was all of the protocols and formats were in text not in binary um and so HTTP is in text by the way and this is an internet tradition by the way that we picked up but we continued it HTTP is text um and HTML is text and then every else everything else that followed is text um as a result and by the way you can imagine purist Engineers saying this is insane you have very limited bandwidth why are you wasting any time sending text you should be encoding the stuff into binary and it'll be much faster and course the answer is that's correct um but what you get when you make it text is all of a sudden well the big breakthrough was the view Source function right so the fact that you could look at a web page you could hit view source and you could see the HTML that was how people learned how to make web pages right it's so interesting because the stuff we take for granted now is uh uh man that was fundamental to the development of the web to be able to have HTML just right there all the ghetto mess that is HTML all the sort of almost biological like messiness of HTML and then having the browser tried to interpret that mess yeah exactly to show something reasonable well and then there was this internet principle that we inherited which was emit what was it emit cautiously emit conservatively interpret liberally so it basically meant if you're the design principle was if you're if you're creating like a web editor that's going to Emmit HTML like do it as cleanly as you can but you actually want the browser to interpret liberally which is you actually want users to be able to make all kinds of mistakes and for it to still work yeah and so the browser rendering engines to this day have all of this spaghetti code crazy stuff where they can they're they're resilient to all kinds of crazy HML mistakes and so and literally what I always had in my head is like there's an eight-year-old or an 11-year-old somewhere and they're doing a view Source they're doing a cut and paste and they're trying to make a web page for their turtle or whatever and like they leave out a slash and they leave out an angle bracket they do this and they do that and it still works it's it's it's also like I don't often think about this but you know programming you know C++ C C++ all those languages lisp the compil languages the interpreted languages python Pearl all that they the brace have to be all correct like everything has to be perfect brutal and then autistic you forget all right it's systematic and rigorous let's go there but you forget that the uh uh the web with JavaScript eventually uh and HTML is allowed to be messy in the way for the first time messy in the way biological systems could be messy it's like the only thing computers were allowed to be messy on for the first time it used to offend me so I I I grew up on Unix I I I I worked on Unix I was a Unix native for all the way through this period um and so and it used to drive me bananas when it would do the the segmentation fault in the Cump file just like it's you know it's like literally there's like an error in the code the math is off by one yeah and it dumps and I'm in the dump try toal it and try to reconstruct I'm just like this is ridiculous like the computer ought to be smart to be able to know that if it's off by one okay fine and it keeps running and I would go ask all the experts like why can't it just keep running and they'd explain to me well because all the downstream repercussions and blah blah and I'm like the still like you know this is we're forcing the human Creator to live to your point in this hyper literal literal world of perfection yeah and I was just like that's just that's just bad and by the way you know what happens with that just what what happened with with coding at that point which is you get a high priesthood you know there's a small number of people who are really good at doing exactly that most people can't and most people are excluded from it and so actually that that was where that for was where I picked up that idea was um uh was like no no you want you want you want these things to be resilient error in all kinds and this this would drive the purist absolutely crazy like I got attacked on this like a lot because yeah I mean like every time I you know all the purists who were like into all this like markup language stuff and formats and codes and all this stuff they would be like you know you can't you're you're encouraging bad behavior because oh so they wanted the browser to give you an a Segall error any times there was a yeah yeah they wanted it to be a cop right they wanted yeah that that was a very and any any any properly trained and credential engineer would be like that's not how you build these system that's such a bold move to say no it doesn't have to be yeah now like I said the the good news for me is the internet kind of had that tradition already um but we but having said that like we pushed it we pushed it way out but the other thing we did going back to the performance thing was we gave up a lot of performance we made that that initial experience for the first few years was pretty painful but but the the bet there was actually an economic bet which was basically the demand for the web would basically mean that there would be a surge and supply of broadband like we because the question was okay how do you get how do you how do you get the phone companies which are not famous in those days for doing new things at huge cost for like speculative reasons like how do you get them to build out Broadband you know spend billions of dollars doing that and you know you could go meet with them and try to talk them into it or you could just have a thing where it's just very clear that's it's going to be that they the people love that's going to be better if it's faster and so that that there there was a period there and this was this was Frau with some Peril but there was a period there where it's like we knew the experience was sub-optimized because we were trying to force the emergence of demand for Broadband sure which is in fact what happened so you have to figure out how to display this text html text so the Blue Links and the purple links what and there's no standards is there standards at that time there really still isn't well there's like there's implied implied standards right and they you there's are all these kinds of new features that are being added with like CSS what like what kind of stuff a browser should be able to support features within languages within JavaScript and so on but you you B you're setting standards on the fly yeah yourself yeah well to this day if you if you create a web page that has no CSS stylesheet the browser will render it however it wants to yeah right so this was one of the things there was this idea this idea at the time and how these systems were built which is separation of content from format or separation of uh yeah content from appearance MH um and that's still people don't really use that anymore because everybody wants to determine how things look and so the ucss but um it's still in there that you can just let the browser do all the work I still like the like uh really basic websites but that could be just old school kids these days with they're fancy responsive websites that don't actually have much content but have a lot of visual elements well that's one of the things that's fun about chat you know about chat GPT just like to the basics back to just text yeah right and you know there is this pattern in human creativity and media where you end up back at text and I think there's you know there's something powerful on there is there some other stuff you remember like the purple links there were some interesting design decisions that to kind of come up that uh we have today or we don't have today that were temporary so uh we made I made the background great I hated reading text on white uh backgrounds and so I made the background gray everybody complain you regret no you regret this no no no that's that decision I think has been reversed um but but now I'm happy though because now dark mode is the thing so so it wasn't about gray it was just you didn't want white back on strain my eyes strain your eyes interesting um and then there's a bunch of other decisions I'm sure there's an interesting history of the development of HTML and CSS and how those in interface in JavaScript and then there's this whole Java applet thing well the big one probably JavaScript CSS was after me so I didn't know was not me but um JavaScript was the big JavaScript maybe was the biggest of the whole thing that was us um and um and that was basically a bet there's a bet on two things one is that the world wanted a new front-end scripting language um and then the other was we I thought at the time the world wanted a new backend scripting language um so JavaScript was designed from the beginning to be both front end and backend and then it failed as a backend scripting language and uh Java won um for a long time and then python Pearl and other things PHP um and Ruby but now JavaScript is back and so I wonder if everything in the end will run on JavaScript it see it seems like it is the um and by the way let me give a shout out to to um uh uh Brandon Ike uh was the basically the onean inventor of um of JavaScript if you're interested to learn more about Brandon Ike he's been on this podcast previously exactly so he wrote JavaScript over a summer um and it it I I mean I think it is fair it is fair to say now that it's the most widely used language in the world and it seems to only be gaining in in um in its uh in its range of adoption you in the software world there's quite a few stories of somebody over a weekend or over a week or over a summer writing some of the most uh impactful revolutionary pieces of software ever that that should be inspiring yes very inspiring I'll give you another one SSL um so SSL was the security protocol that was us and that was a crazy idea at the time which was let's take all the native protocols and let's wrap them in a security rapper that was a guy named Kip Hickman who wrote that over a summer one guy um and then look today sitting here today like the transformer like at Google was a small handful of people and then you know the number of people who have did like the core work on GPT it's not that many people a pretty small handful of people um and so yeah the pattern in software repeatedly over a very long time has been it's it's a Jeff Jeff Bezos always had the two Pizza rule uh for teams at Amazon which is any team needs to be able to be fed with two pizzas if you need the third Pizza you have too many people and I think that's I think that's I think it's actually the one pizza rule yeah for the for the really creative work I think it's two people three people well that's you see that with certain open source projects like so much is done by like one or two people like it's it's so incredible and that's why you see that gives me so much hope about the open source movement in this new age of AI where um you just recently having had a conversation with with Mark Zuckerberg of all people who's all in on open source which is so interesting to see and so inspiring to see cuz like releasing these models it is scary it is potentially very dangerous and we'll talk about that but it's also if you believe in the goodness of most people and in the skill set of most people and the desire to go do good in the world that's really exciting cuz it's not putting it these models into the centralized control of big corporations the government and so on it's putting it in the in the hands of a teen teenage kid with like a dream in his eyes I don't know that's um that's beautiful and look this stff AI to make the individual coder obviously far more productive right by like you know a THX or something and so you uto open source like not just the future of Open Source but the future of Open Source everything we ought to have a world now of super coders right who are building things as open source with one or two people that were inconceivable you know five years ago um you know the level of kind of hyper productivity we're going to get out of our best and brightest I think is going to go way up it's going to be interesting we'll we'll talk about it but let's just to linger a little bit on Netscape Netscape was was acquired in 1999 for 4.3 billion by AOL what was that uh what was that like what was what were some memorable aspects of that well that was the height of the do boom bubble bust I mean that was the that was the frenzy um if you watch a succession that was the that was like what they did in the fourth season with uh the with Gojo and the merger with the with their so it was like the height of like one of those kind of Dynamics and so would you recommend succession by the way I'm more of a Yellowstone guy Yellowstone's very American I'm I'm very proud of you that's that is I just talked to Matthew mccon and I'm full on texting at this point good I hardly approve um and uh he will be doing the sequel to Yellowstone so very exciting anyway I can't wait uh so that's a rude Interruption by me uh by way of succession uh so that was at the height of the deal making and money and just the fur flying and like craziness and so yeah it was just one of those it was just like I mean the entire ncape thing from start to finish was four years um which was like for for one of these companies it's just like incredibly fast you know it we went public 18 months after we got after we were founded which virtually never happens so it was just this incredibly fast kind of meteor streaking across the sky um and then of course it was this and then there was just this explosion right that happened because then it was almost immediately followed by the Doom Crash It Was Then followed by AOL buying Time Warner which again as the succession guys kind of play with that uh which turned out to be a disastrous deal um one of the famous you know kind of disastrous in business history um and then um and then you know what became an internet depression on the other side of that but then in that depression in the 2000s was the beginning of broadband and smartphones and Web 2.0 right and then social media and search and every SAS and everything that came out of that so what did you learn from just the the acquisition I mean this is so much money yeah what you what what's interesting cuz I I must have been very new to you that these software stuff you can make so much money there's so much money swimming around I mean I'm sure the ideas of investment was starting to get born there yes let me get so let me lay it l so here's here's the thing I I don't know if I figured out them but figured it out later which is um software is a technology that it's like a you know the concept of the philosopher stone the philosopher stone in alchemy transmutes Le into gold and Newton spent 20 years trying to find the philosopher stone never got there nobody's ever figured it out software is our modern philosopher stone and in economic uh terms it transmutes labor into Capital which is like a super interesting thing and by the way like Carl Mark is rolling over in his grave right now because of course that's complete reputation of his entire Theory um transp labor into Capital which is which is as follows is somebody sits down at a keyboard and types A bunch of stuff in and a capital asset comes out the other side and then somebody buys that Capital asset for a billion dollars like that's amazing right it's literally creating value right out of thin air right out out of purely human thought right um and so that that that's there are many things that make software magical and special but that's the economics I wonder what Marx would have thought about that oh he would have completely broke his brain because of course the whole the whole thing was it was he you know that kind of technology is inconceivable when he was alive it was all it was all industrial era stuff and so the any kind of Machinery necessarily involved huge amounts of capital and then labor was on the on on the receiving end of the abuse yep um right but like software software a software engineer or somebody who basically transmutes his own labor into act an actual Capital asset um creates permanent value well in fact it's actually very inspiring um that's actually more true today than before so when when I was doing software the Assumption was all new software basically has a sort of a a parabolic sort of life cycle right so you you ship the thing people buy it at some point everybody who wants it has bought it and then it becomes Obsolete and it's like bananas nobody nobody buys old software um these days um Minecraft um Mathematica you know Facebook Google um you have the software assets that are you know have been around for 30 years that are gaining in value every year right and they're just there being world Warcraft right salesforce.com like they're being every single year they're being polished and polish and polish and polish they're getting better and better more powerful more powerful more valuable more valuable so we we've entered this era where you can actually have these things that actually build out over decades which by the way is what's happening right now with like GPT um and so um now and this is why you know there there there is always you know sort of a constant investment frenzy around software is because you know look when you start one of these things it doesn't always succeed but when it does now you might be building an asset that builds value for you know four five six decades to come um you know if you have a team of people who have the level of devotion required to keep making it better and then the fact that of course everybody's online you know there's five billion people that are a click away from any new piece of software so the potential Market size for any of these things is you know nearly infinite it must have been surreal back then though yeah yeah this was all brand new right yeah back then this was all brand new these were all you know brand new had you rolled out that theory in even 1999 people would have thought you were smoking crack so that that's that's emerged over time well let's uh now turn back into the future you wrote the essay why AI will save the world let's start at the very high level what's the main thesis of the essay yeah so the main thesis on the essay is that what we're dealing with here is intelligence um and it's really important to kind of talk about the sort of very nature of what intelligence is and fortunately we have a we have a predecessor to machine intelligence which is human intelligence and we've got you know observations and theories over over thousands of years for what what what intelligence is in the hands of of humans and and what intelligence is right I mean what it what it literally is is the way to uh you know capture process analyze synthesize information solve problems um but the observation of of of intelligence in human hands is that intelligence quite literally makes everything better um and what I mean by that is every kind of outcome of like human quality of life whether it's education outcomes or success of your children or Career Success or health or lifetime satisfaction um by the way um uh uh propensity to peacefulness as opposed to violence uh propensity for open-mindedness uh versus bigotry um those are all associated with higher levels of intelligence smarter people have better outcomes than almost as you right in almost every domain of activity academic achievement job performance occupational status income creativity physical health longevity learning new skills managing complex tasks leadership entrepreneurial success conflict resolution reading comprehension Financial decision-making understanding others perspectives creative arts parenting outcomes and life satisfaction one of the more depressing conversations I've had and I don't know why it's depressing I have to really think through why it's depressing but on IQ mhm and uh the G factor and that that's something in large part is genetic and it correlates so much with all of these things and success in life it's like all the inspirational stuff we read about like if you work hard and so on damn it sucks that you're born with the hand that you can't change but what if you could you're you're saying basically a really important point I think it's a uh in in your articles what it it really helped me um it's a nice added perspective to think about listen human intelligence the science of intelligence has shown scientifically that it just makes life easier and better the smarter you are and now let's look at artificial intelligence and if uh that's a way to increase the the the sum human intelligence then uh it's only going to make a better life yeah that's the argument and certainly at the collective level we could talk about the collective effect of just having more intelligence in the world which which will have very big payoff but there's also just at the individual level like what if every person has a machine you know and concept of augment Doug ankle Bar's concept of augmentation um you know what if everybody has a an assistant and the assistant is you know 140 IQ um and you happen to be 110 IQ um and you've got you know something that basically is infinitely patient and knows everything about you and is pulling for you in every possible way wants you to be successful and anytime you find anything confusing or want to learn anything or have trouble understanding something or want to figure out what to do in a situation right want to figure out how to prepare for a job interview like any of these things like it will help you do it and it will therefore the combination will effectively be you know effectively raise your raise because it will effectively raise your IQ will therefore raise the odds of of successful life outcomes in all these areas so people below the this hypothetical 140 IQ it'll pull them off towards the 140 IQ yeah yeah yeah and then of course you know people at people at 140 IQ will be able to have a peer right to be able to commun which is great people above 140 IQ will have an assistant that they can Farm things out to and then look God willing you know at some point these things go from future versions go from 140 IQ equivalent to 150 to 160 to 180 right like Einstein was estimated to be on the order of 160 um you know so when we get you know 160 AI like we'll be you know when one assumes creating Einstein level breakthroughs and physics and and then and then at 180 we'll be you know curing cancer and developing warp drive and doing all kinds of stuff and so it is quite possibly the case this is the most important thing that's ever happened and the best thing that's ever happened because precisely because it's a lever on this single fundamental factor of intelligence which is the thing that drives so much of everything else can you still man the case that human plus AI is not always better than human for the individual you may have noticed that there's a lot of smart assholes running around sure yes right and so like smart there are certain people where they get smarter you know they they get to be more arrogant right so you know there's one huge flaw although to push back on on that it might be interesting because when the intelligence is not all coming from you but from a Sy from another system that might actually increase the the amount of humility even in the assholes one would hope um or it could make assholes more assholes you know that's I mean that's that's for psychology to study yeah exactly another one is um smart people are very convinced that they you know have a more rational view of the world and that they have a easier time seeing through conspiracy theories and hoaxes and right you know sort of crazy beliefs and all that there there's a theory psychology which is actually smart people so for sure people who aren't as smart are very susceptible to hoaxes and conspiracy theories but it may also be the case that the smarter you get you become susceptible in a different way uh which is you become very good at marshalling facts to fit preconceptions yes right um you become very very good at assembling whatever theories and Frameworks and pieces of data and graphs and charts you need to validate whatever crazy ideas got into your head and so you're susceptible in a different way right uh we're all sheep but different colored sheep some sheep are better at justifying it right um and those are the you know those are the smart sheep right um so yeah look like it I would say this look like there are no panace I not I not a utopian there are no panaceas in life um there are no like you know I don't believe there are like pure positives I'm not a transcendental kind of person like that but you know so yeah there are going to be issues um uh and um and you know look smart people another maybe you could say about smart people is they are more likely to get themselves in situations that are you know beyond their grasp you know because they're just more confident that their ability to deal with complex and their their eyes become bigger their cognitive eyes become bigger than their stomach M you know so yeah you could argue those eight different ways nevertheless on net right clearly overwhelmingly again if you just extrapolate from what we know about human intelligence you're you're improving so many aspects of life if you're upgrading intelligence so there'll be assistance at all stages of life so when you're younger there's for Education all that kind of stuff from mentorship all all of this and uh later on as you're doing work and you've developed the skill and you're having a profession you have an assistant that helps you excel at that profession so at all stages of Life yeah I mean look the theory is augmentations this is the dle Bart's term for dle Bart made this observation many many decades ago that you know basically it's like you can have this oppositional frame of Technology where it's like us versus the machines but what you really do is you use technology to augment human capabilities yeah and and by the way that's how actually the economy develops that's we can talk about the economic side of this but that that's actually how the economy grows um is through through technology augmenting human human potential um and so yeah and then you you basically have a a proxy or you know or or a um you know a sort of prosthetic um you know so like you've got glasses you've got a wristatch you know you've got shoes you know you've got these things you've got a personal computer you've got a word processor you've got Mathematica you've got Google this is the lat viewed through that lens AI is the latest in a long series of basically augmentation methods uh to be able to raise human capabilities it's just this one is the most powerful one of all because this is the one that that goes directly to what what they call fluid intelligence mhm which is IQ well there's uh two categories of folks that you outline that uh that worry about or highlight the risks of AI and you highlight a bunch of different risks i' would love to go through those risks and just discuss them brainstorm which ones are serious and which ones are less serious but first the the Baptist and the Bootleggers what are these two interesting groups of folks who uh who who worry about uh the effect of AI human civilization or say they do say say okay yes I say they do the Baptists worry the boot leers say they do yeah um so the Baptist and the Bootleggers is a metaphor from economics um from what's called development economics and it's this observation that when you get social reform movements um in a society um you tend to get two sets of people showing up arguing for the social reform um and the the term Baptist and Bootleggers comes from the American experience with alcohol prohibition um and so in the 1900s 1910s um there was this movement that was very passionate at the time which basically said alcohol is evil uh and it's destroying Society um by the way there was a lot of evidence to support this um there were very high rates of uh very high correlations then by the way and now uh between rates of physical violence and alcohol use um almost all violent crimes have either the perpetrator or the victim or both drunk almost if you see this actually in the work almost all sexual harassment cases in the workplace it's like at a company party and somebody's drunk like it's it's amazing how often alcohol actually correlates to actually just dysfunction it leads to domestic abuse um and so forth child abuse and so you had this group of people who were like okay this this is bad stuff and we should Outlaw it and and those were quite literally Baptists those were super committed you know hardcore Christian activists in a lot of cases there was this woman uh whose name was Carrie Nation um who was this older woman who had been in this you know I don't know disastrous marriage or something and her husband had been abusive and drunk all the time and she became the icon of the Baptist uh prohibitionists and she was legendary in that era for carrying axe um and doing you know completely on her own doing raids of saloons and like taking her axe to all the bottles and TS in the back and and so so a True Believer an absolute True Believer um and with absolutely the purest of intentions and and again there's a very important thing here which is there's you could look at this cynically and you could say the Baptists are like delusional you know extremists but you could also say look they're right like she was you know she had a point like she wasn't wrong um about a lot of what she said y but it turns out the way The Story Goes is turns out that there were another set of people who very badly wanted to outlaw alcohol in those days and those were the Bootleggers which was organized crime that stood to make a huge amount of money if legal alcohol sales were banned um and this was in fact the way the history goes is this was actually the beginning of organized crime in the US this was the big Economic Opportunity that open that up um and so they went in together um and they didn't go in together like the Baptist did not even necessarily know about the Bootleggers because they were on their moral Crusade the Bootleggers certainly knew about the Baptists and they were like wow this is these people are like the Great people for like you know Shenanigans in the background and they got the Volstead Act passed right and they did in fact ban alcohol in the US and you'll notice what happened which is people kept drinking it didn't work people kept drinking um that Bootleggers made a tremendous amount of money um and then over time it became clear that it made no sense to make it illegal and it was causing more problems and so then it was revoked and here we sit with legal alcohol 100 years later with all the same problems um and you know the whole thing was this like giant misadventure uh the Baptist got taken advantage of by the bootleggers and the Bootleggers got what they wanted and and that was that the same two categories of folks are now uh sort of suggesting that uh the development of artificial intelligence should be regulated 100% yeah it's the same pattern the economists will tell you it's the same pattern every time like this is what happened with nuclear power this is what Happ which is another interesting one but like yeah this is this happens dozens and dozens of times um throughout the last 100 years and and and this is what's happening now and you write that it isn't sufficient to Simply identify the actors and imp their motives we should consider the arguments of both the Baptists and the Bootleggers on their merits so let's do just that risk number one uh will AI kill us all yes so uh what do what do you think about this one this this what do you think is the core argument here that uh the development of AGI perhaps better said uh will destroy human civilization well first of all you just did a slight of hand because we went from talking about AI to AGI is there a fundamental difference there I don't know what's AGI I what's AI what's intell I know what AI is AI is machine learning what's what's AGI I think we don't know what the bottom of the well of machine learning is or what the ceiling is cuz just uh to call something machine learning or just to call something statistics or just to call math or computation doesn't mean you know uh nuclear weapons are just physics so it's it it's to me it's very interesting and surprising how far machine learning has taken no but we knew that nuclear physics would lead to weapons that's why the scientists of that era we're always in this huge dispute about building the weapons this is different a is different where does machine learning lead do we know we don't know but this is my point it's different we we actually don't know but and and this is where you the slight of hand kicks in right this is where it goes from being a scientific topic to being a religious topic um and that's that's why I specifically called out that because that's what happens they do the vocabulary shift and all of a sudden you're talking about something totally that's not actually real well then maybe you can also uh as part of that Define the Western tradition of millennialism yes end of the world apocalypse apocalypse apocalypse Cults um apocalypse Cults well so we live in we of course live in a judeo-christian but primarily Christian kind of saturated you know kind of Christian post-christian secularized Christian you know kind of world in the west um and of course core of Christianity is the idea of the second coming and and re you know Revelations and you know Jesus returning and th the Thousand Year you know Utopia on Earth and then the you know the rapture and like all all that stuff you know we don't we you know we collectively you know as a society we don't necessarily take all that fully seriously now so what we do is we create our secularized versions of that we keep we keep looking for Utopia we keep looking for you know basically the end of the world and so what what you see over over decades is basically a pattern of these sort of of these of these of is this this is what Cults are this is how Cults form as they form around some theory of the end of the world and so the people's Temple Cults the Manson cult the Heaven's Gate cult the David Kesh cult you know what they're all organized around is like there's going to be this thing that's going to happen that's going to basically bring civilization crashing down and then we have this special Elite group of people who are going to see it coming and prepare for it and then they're the people who are either going to stop it or are failing stopping it they're going to be the people who survived to the other side and ultimately get credit for having been right why is that so compelling do you think like uh because it satisfies this very deep need we have for Transcendence and meaning that got Stripped Away when we became secular yeah but why why is the Transcendence involve the destruction of human civilization cuz like how like how plausible it's it's like a very deep psychological thing CU it's like how plausible how plausible is it that we live in a world where everything's just kind of all right right how exting how exciting is that right that's we want more than that but that's the Deep question I'm asking why is it not exciting to live in a world where everything's just all right does it I think uh you know most of the animal kingdom would be so happy we just all right cuz that means surv rival why are we uh maybe that's what it is why are we Conjuring up things to worry about so CS Lewis called it the god-shaped hole so there's a god-shaped hole in The Human Experience Consciousness Soul whatever you want to call it where there's got to be something that's bigger than all this there's got to be something Transcendent there's got to be something that is bigger right bigger a bigger purpose a bigger meaning and so we have run the experiment of you know we're just going to use science and rationality and kind of you know everything just going to kind of be as it appears and a large number of people have found that very deeply wanting and have constructed narratives and and by this is the story of the 20th century right communism right was one of those communism was a was a form of this Nazism was a form of this um you know some people um you know you can see movements like this playing out all over the world right now so you construct a kind of devil a kind of source of evil and we're going to transcend Beyond it yeah the millenarian the millenarian kind of when you see millenarian cult they put a really specific point on it which is end of the world right there there there is some change coming and that change that's coming is so profound and so important that it's either going to lead to Utopia or hell on Earth right um and it is going to and then you know it's like what if you actually knew that that was going to happen right what would you what what would you do right how would you prepare yourself for it how would you come together with a group of like-minded people right how would you what would you do would you plan like cashes of weapons in the woods would you like you know I don't know with create under underground bunkers would you you know spend your life trying to figure out a way to avoid having it happen yeah that's a really compelling exciting idea to uh to have a club over to have to to have a to have a little bit of tribe like you get together on a Saturday night and drink some beers and talk about the the end of the world and how you the you are the only ones who have figured it out yeah and then and then once you lock in on that like how can you do anything else with your life like this is obviously the thing that you have to do and then and then there's a psychological effect that you alluded to there's a psychological effect if you take a set of True Believers and you leave them to themselves they get more radical right because they they self- radicalize each other that said yes it doesn't mean they're not sometimes right yeah the end of the world might be yes correct like they might be right yeah but like we I have some pamphlets for you exactly it's it I mean there's I mean we'll talk about nuclear weapons because you have a really interesting little moment that I learned about in in your essay but you know sometimes it could be right yeah CU we're still you were developing more and more powerful Technologies uh in this case and we don't know what the impact it will have on human civilization well we can highlight all the different predictions about how it will be positive but the risks are there and you discuss some of them well the Steel Man the steel man is the steel man well actually the steel man and his reputation are the same which is you can't predict what's going to happen right you right you can't rule out that this will not end everything right but the response to that is you have just made a completely non-scientific claim yeah you've made a religious claim not a scientific claim there how does it get disproven there is and there's no by definition with these kinds of claims there's no way to disprove them yeah right um and so there there's no you go right on the list there's no hypothesis there's no testability of the hypothesis there's no um way to falsify the hypothesis there's no way to measure progress along the arc like it's just all completely missing and so it's not scientific and well I don't I don't think it's completely missing it's it's somewhat missing so for example the the the the people that say AI is going to kill all of us I mean they usually have ideas about how to do that whether it's the pap maximizer or um you know it escapes there's mechanism by which you can imagine it killing all humans models and to you can disprove it by saying there is um there is a limit to uh the speed of which intelligence increases maybe show that uh like sort of rigorously really describ model like how it could happen and say no there here's a physics limitation there's a physical limitation to how these systems would actually do damage on human civilization and it is possible they will kill 10 to 20% of the population but it seems impossible for them to kill uh 99% it was practical counterarguments right so you mentioned basically what I described as the thermodynamic counterargument which sitting here today it's like where with the evil AGI get the gpus yeah because like they don't exist so you're gonna have a very frustrated baby evil AGI who's going to be like trying to buy Nvidia stock or something to get them to finally make some chips um right so the serious form of that is the thermodynamic argument which is like okay where's the energy going to come from where's the processor going to be running where is the data center going to be happening how is this going to be happening in secret such that you know it's not you know so so that's a practical counterargument to The Runaway AGI thing I have a but I have a and we can argue that and discuss that I I have a deeper objection to it which is it's this is all forecasting it's all modeling it's all it's all future prediction it's all future hypothesizing it's not science sure it is not is is is the opposite of science so the pull up Carl Sean extraordinary claims require extraordinary proof right these are extraordinary claims the policies that are being called for right to prevent this are of extraordinary magnitude and I think we're going to cause extraordinary damage and this is all being done on the basis of something that is literally not scientific it's not a testable hypothesis so the moment you say AI is going to kill all of us therefore we should ban it or the we should uh regulate all that kind of stuff that's when it starts getting serious or start you know military air strikes and data centers oh boy right and like yeah one get starts starts getting real so here's the problem with millonary and Cults they have a hard time staying away from violence yeah but violence is so fun if you're on the right end of it they have a hard time avoiding violence the reason they have a hard time avoiding violence is if you actually believe the claim right then what would you do to stop the end of the world you would do anything right and so and this is where you get again if you just look at the history of of millenarian Cults this is where you get the people's Temple and everybody killing themselves in the jungle and this is where you get Charles Manson and you know sending in to kill kill the pigs like this is the problem with these they they have a very hard time draw the line at actual violence and I think I think in this case there's they're I mean they're already calling for it like today and you know where this goes from here as they get more worked up like I I think is like really concerning okay but that's kind of the extremes you know the extremes of anything are always concerning it's also possible to kind of believe that AI has a very high likelihood of killing all of us uh but there's and therefore we should uh maybe consider uh slowing development or regulating so not violence or any of these kinds of things but saying like all right let's let's take a pause here you know you biological weapons nuclear weapons like whoa whoa whoa whoa whoa this is like serious stuff we should be careful so it is possible to kind of have a more rational response right if you believe this risk is real believe yes so what is it possible to be have a scientific approach to the the the prediction of the future I mean we just went through this with Co yeah what do we know about modeling well I mean what do we learn about modeling with co uh there's a lot of lessons they didn't work at all they worked poorly the models were terrible the models were useless I don't know if the models were useless or the people interpreting the models and then the centralized instit tions that were creating policy rapidly based on the models and leveraging the models in order to uh support their narratives versus actually interpreting the airb bars and the models and all that kind of stuff what you had with Co my my view you had with Co is you had these experts showing up they claimed to be scientists and they had no testable hypothesis whatsoever they had a bunch of models um they had a bunch of forecasts and they had a bunch of theories and they laid these out in front of policy makers and policy makers freaked out and panicked right and implemented a whole bunch of like really like terrible decisions that we're still living with the consequences of um and there was never any empirical Foundation to any of the models none of them ever came true yeah to push to push back there were certainly Baptist and Bootleggers in this in the context of this pandemic but there's still a usefulness to models no I I so not if they're I mean not if they're reliably wrong right then they're actually like anti-us right they're actually damaging but what what do you do with a pandemic what do you do with a with a with any kind of threat don't you want to kind of have um several models to play with as part of the discussion of like what the hell do we do here I mean do they work is there an expectation that they actually like work that they have actual predictive value I mean as far as I can tell with Co we just the the policy makers just SC up themselves into believing that there was subst I mean look the scientist the scientists were at fault this the quote unquote scientists showed up so I had some insight into this so there there was a remember the Imperial College models out of out of London were the ones that were like these are the gold standard models yeah so a friend of mine runs a big software company and he was like wow this is like CO's really scary and he's like you know he contacted This research and he's like you know do you need some help you've been just building this model on your own for 20 years do you need some you like our coders to basically restructure it so it can be fully adapted for Co and the guy said yes and sent over the code and my friend said it was like the worst spaghetti code he's ever seen that doesn't mean it's not possible to construct a good model of pandemic with a correct air bars with a high number of parameters that are continuously many times a day updated as we get more data about a pandemic I would like to believe when a pandemic hits the world the best computer scientist in the world the software Engineers respond aggressively and as input take the data that we know about the virus and as an output say here's here's what's happening in terms of how quickly it's spreading what that lead in terms of hospitalization and deaths and all that kind of stuff here's How likely how contagious it likely is here's how deadly it likely is based on different conditions based on different ages and demographics and all that kind of stuff so here's the best kinds of policy it feels like you can have models machine learning that like kind of they don't perfectly predict the future but they they they help you do something because there's pandemics that are like uh meh they don't really do much harm and there's pandemics you can imagine them they could do a huge amount of harm like they can kill a lot of people so you should probably have some kind of datadriven models that keep updating that allow you to make decisions that based like where how bad is this thing uh now you can criticize how horrible all that went with the response to this pandemic but I just feel like there might be some value to models so to be useful at some point it has to be predictive right so and so and and so the easy thing for me to do is to say obviously you're right obviously I want to see that just as much as you do because anything that makes it easier to navigate through Society through a wrenching you know risk like that is you sound that sounds great um you know the the harder objection to it is just simply you are trying to model a complex dynamic system with 8 billion moving Parts like not possible can't be done complex systems can't be done uh machine learning says hold my beer but well it's possible no I don't know I I would like to believe that it is yeah put it this way I think where you and I would agree is I think we would like we would we' like that to be the case we are strongly in favor of it I think we would also agree that no such thing with respect to co or pandemics no such thing well at least neither you nor I think are aware I'm not aware of anything like that today my main worry with the response to the pandemic is that uh uh same as with aliens is that even if such a thing existed and it's possible it existed the the the the policy makers were not paying attention like U there was no mechanism that allowed those kinds of models to percolate up oh I think we had the opposite problem during Co I think the policy makers I think the these the these these people with basically fake science had too much access to the policy makers right and but the policy makers also wanted they had a narrative in mind and they also wanted to use whatever model that fit that narrative to help them out so like it felt like there was a lot of politics and not enough science yeah although a big part of what was happening a big a rig reason we got lockdowns for as long as we did was because these scientists came in with these like Doom State scenarios that were like just like completely off the hook scientists and quotes not quotequote scientist not okay let's give love science that is the way out science is a process of testing hypothesis yeah modeling does not involve testable hypotheses right like I don't even know that I actually don't I I don't even know that modeling actually qualifies as science maybe that's a side conversation we could have sometime over a beer it's really interesting but what do we do about the future I mean what what so number one is when we start with number one humility goes back to this thing of how do we determine the truth number two is we don't believe you know it's the old I've got a hammer everything looks like a nail right um I've got oh this one of the reasons I gave you I gave Lex a book um which the topic of the book is what happens when scientists basically stray off the path of technical knowledge and start to weigh in on politics and societal issues um in this case philosophers well in this case philosop first but he he actually talks in this book about like Einstein he talks actually about the nuclear age and Einstein he talks about the physicists uh actually doing doing very similar things at the time uh the book is when reason goes on holiday philosophers and politics by uh Nevin and it's just a story it's a story there's there are other books on this topic but this is a new one that's really good it's just the story of what happens when experts in a certain domain decide to weigh in and become basically social engineers and and political um you know basically political advisers and it's just a story of just unending catastrophe right and I think I think that's what happened with Co again yeah I found this book a highly entertaining and eye-opening read filled with amazing anecdotes of irrationality and craziness by famous recent philosophers this if you read this book you will not look at Einstein the same oh boy yeah don't destroy my hero you will not be a hero of yours anymore um I'm sorry you probably should you shouldn't read the book all right but here's the thing the AI the AI risk people they don't even have the co model at least not that I'm aware of no like there's not equivalent to the co model they don't even have the spaghetti code they've got a theory and a warning and a this and a that and like if you ask like okay well here's here's you I mean the ultimate example is okay how do we know right how do we know that an AI is running away like how do we know that the fum takeoff thing is actually happening and the only answer that any of these guys have given that I've ever seen is oh it's when the loss rate the loss function in in the training drops right that's when you need to like shut down the data center right and it's like well that's also what happens when you're successfully training a model like like what what even is this is not science this is not it's not anything it's not a model it's not anything there's nothing to arguing with it as like you know punching Jello like there there's what do you even respond to so just push back on that I don't think they have good metrics of yeah when the fum is happening but I think it's possible to have that like I just just as you speak now I mean it's possible to imagine that could be measures it's been 20 years no for sure but it's been only weeks since we had a big enough breakthrough in language models we can start to actually have this the thing is the AI Doomer stuff didn't have any actual systems to really work with and now there's real systems you can start to analyze like how does this stuff go wrong and I think you kind of agree that there is a lot of risks that we can analyze the benefits outweigh the risks in many cases well the risks are not existential yes well not in the not not in the F not in the F paperclip so let me okay there's another slide of hand that you just alluded to there's another slide of hand that happens which is very I think I'm very good at the slide of hand which is very not scientific so the book super intelligence right which is like the Nick Bost book which is like the origin of a lot of this stuff which was written you know whatever 10 years ago or something so he does this really fascinating thing in the book which is he basically says um uh there are many possible routes to machine intelligence um to artificial intelligence and he describes all the different routes to artificial intelligence all the different possible everything from biological augmentation through to you know all these different things um one of the ones that he does not describe is large language models because of course the book was written before they were invented and so they didn't exist in the book he he describes them all and then he proceeds to treat them all as if they're exactly the same thing he presents them all as sort of an equivalent risk to be dealt with in an equivalent way to be thought about the same way and then the risk the quote unquote risk that's actually emerged is actually a completely different technology than he was even imagining and yet all of his theories and beliefs are being transplanted by this movement like straight on this new technology and so again like there's no other area of science or technology where you do that yeah like when you're dealing with like organic chemistry versus inorganic chemistry you don't just like say oh with respect to like either one basically maybe you know growing up and eating the world or something like they're just going to operate the same way like you don't but you can start talking about like as as we get more and more actual systems that start to get more and more intelligent you can start to actually have more scientific arguments here oh like you know high level you can talk about the threat of autonomous weapon systems back before we had any Automation in in the military and that would be like very fuzzy kind of logic but the more and more you have drones they're becoming more and more autonomous you can start imagining okay what does that actually look like and what's the actual threat of autonomous weapon systems How does it go wrong and still it's it's it's very vague but you start to get a sense of like all right um it should probably be illegal or or wrong or not allowed to do like Mass deployment of fully autonomous drones that are doing aerial strikes oh no lar areas I think it should be required right so that's no no no no I think it should be required that only aerial vehicles are automated okay so you want to go the other way I want to go the other way so that okay I think it's obvious that the machine is going to make a better decision than the human pilot I think it's obvious that it's in the best interest of both the attacker and the defender and Humanity at large if machines are making more of these decisions and not people I think people make terrible decisions in times of War but like there's a there's ways this can go wrong too right well the wars go terribly wrong now this goes back to the this is that whole thing about like the self does the self driving car need to be perfect versus does it need to be better than the human driver yeah does the automated drone need to be perfect or does it need to be better than a human pilot at making decisions under enormous amounts of stress and uncertainty yeah well the on average right the the worry that AI folks have is the runaway they're going to come alive right then again that's the slight of hand right or not not come alive no hold on a second you lose control well but then they're going to develop goals of their own they're going to develop a mind of their own they're going to develop their own right no more more like uh Chernobyl style meltdown like uh just bugs in the code accidentally you know Force you like the results in the bombing of like large civilian areas okay to to a degree that's not possible um in the in the current uh military strategies control by humans well actually we've been doing a lot of mass the cities for a very long time yes and a lot of civilians died a lot of civilians died and if you watch the documentary The Fog of War mnam it beens a big part of it talking about the firebombing of the Japanese cities yeah burning them straight to the ground right the the devastation in Japan American Military firebombing the cities in Japan was considerably bigger Devastation than the use of nukes right so we've been doing that for a long time we we also did that to Germany by the way Germany did that to to us right like that's an old tradition the minute we got airplanes we started doing indiscriminate bombing so one of the things we're still doing it modern US uh military can do with technology with automation but technology more broadly is uh higher and higher Precision strikes yeah and so Precision is obviously prec and this is the the jdam right so there was this big Advance this big Advance um called the jdam which basically was trapping a GPS transceiver to a to to an unguided bomb and turning it into a guided guided bomb and yeah that's great like look that's been a big advance but and that's like a baby version of this question which is okay do you want like the human pilot like guessing where the bomb's going to land or do you want like the machine like guiding the bomb to its destination that's a baby version of the question the next version of the question is do you want the human or the machine deciding whether to drop the bomb everybody just assumes the human's going to do a better job for what I think are fundamentally suspicious reasons emotional psychological reasons I think it's very clear that the machine's going to do a better job making that decision because the humans making that making that decision are God awful just terrible yeah right and so so yeah so this is the this is the thing and then let's get to the there was can I one more slight of hand was in please I'm a magician you could say one more slight of hand these things are going to be so smart right that they're going to be able to destroy the world and wreak havoc and like do all this stuff and plan and do all this stuff and evade us and have all their secret things and their secret factories and all this stuff but they're so stupid that they're going to get like tangled up in their code and that's the they're not going to come alive but there's going to be some bug that's going to cause them to like turn a all on a paper like that they're not g that they're going to be genius in every way other than the actual bad goal and it's just like and that's just like a like ridiculous like discrepancy and and and and and you can prove this today you can actually address this today for the first time with LMS which is you can actually ask llms to resolve uh moral dilemas yeah so you can create the scenario you know dot dot dot this that this that this that what would you as the AI do in the circumstance and they don't just say Destroy All Humans Destroy All Humans they will give you actually very nuanced moral practical trade-off oriented answers and so we actually already have the kind of AI that can actually like think this through and can actually like you know reason about goals well the the hope is that AGI or like very super intelligent systems have some of the Nuance that llms have and the intuition is they most likely will because even these llms have the Nuance uh LMS are really this is actually worth worth um spending a moment on LMS are really interesting to have moral conversations with and that I just I didn't expect I'd be having a moral conversation with a machine in my lifetime well and and let's remember we're not really having a conversation with the machine where we're having a conversation with the entirety of the collective intelligence of the human species exactly yes correct but it's possible to imagine autonomous weapon systems that are not using LMS but if they're smart enough to be scary why are they not smart enough to be wise like that's the part where it's like I I don't know how you get the one with that the other is it possible to be super intelligent without being Super Wise well you're again you're back to that I mean then you're back to a classic artistic computer right like you're back to just like a a blind rule follower I've got this like core it's a paperclip thing I've got this core Rule and I'm just going to follow it to the end of the the Earth and it's like well but everything you're going to be doing to execute that rule is going to be super genius level that humans aren't going to be able to counter it's just a it's a it's a mismatch in the definition of of what the system is capable of unlikely but not impossible I think but again here you get to like okay like no but I'm not saying when it's unlikely but not impossible if it's unlikely that means the the fear should be correctly calibrated extraordinary claims require extraordinary proof well okay so one interesting sort of tangent I would love to take on this because he mentioned this in the essay about nuclear which was also I mean you don't shy away from a a little bit of a of a spicy take so uh uh Robert Oppenheimer famously said now I am become death the destroyer of worlds as he witnessed the first detonation of a nuclear weapon on July 16th 1945 and you write an interesting historical perspective uh quote recall that John Van noyman responded to Robert Robert oppenheimer's famous hand rigging about the role of creating nuclear weapons which you note helped end World War II and prevent World War I with some people confess guilt to claim credit for the sin and you also mentioned that Truman was harsher after meeting Oppenheimer he said that uh don't let that cry be being here again real quote real quote by the way from Dean from Dean nerson oh boy CU appenheimer didn't just say the famous line yeah he then spent years going around basically moaning and you know going on TV and going into going into the White House and basically like just like doing this hair shirt you know thing self you know this sort of self-critical like oh my God I can't believe how awful I am so he's the the he's widely considered perhaps of the because the Hang ringing is the father of the atomic bomb uh this is this is vanman criticism of him is he tried to have his cake and eat it too like he he wanted to and and so vanman of course a very different kind of personality and he's just like yeah SC this is like an incredibly useful thing I'm glad we did it yeah oan Norman is as widely um credited as being one of the smartest humans of the 20th century the certain certain people everybody says like this is the smartest person I've ever met when they've met him anyway uh that doesn't mean smart doesn't mean wise so I would love to sort of can you make the case both for and against the critique of Oppenheimer here cuz we're talking about nuclear weapons boy do they seem dangerous well so the critique goes deeper and I let I left this out here's the real substance I left it out cuz I didn't want to dwell on on nukes in my AI paper but here's the deeper thing that happened and I'm I'm really curious this movie coming out this summer I'm really curious to see how far he pushes this because this is the real drama in the story which is it wasn't just a question of our nukes good or bad it was a question of should Russia also have them um and what what actually happened um was Russia got the America invented the bomb Russia got the bomb they got the bomb through Espionage they got American and you know they got American scientists and foreign scientists working on the American project some combination of the two uh basically gave the Russians the designs for the bomb and that's how the Russians got the bomb um there's this dispute to this day of oppenheimer's role in that um if you read all the histories the kind of composite picture and and by the way we now know a lot actually about Soviet Espionage in that era because there's been all this Declassified material in the last 20 years that actually shows a lot of a lot of very interesting things but if you kind of read all the histories what you kind of get is Oppenheimer himself probably was not a he probably did not hand over the nuclear himself however he was close to many people who did including family members and there were other members of the Manhattan Project who were Russian Soviet assets and did hand over the bomb and so the view that Oppenheimer and people like him had that this thing is awful and terrible and oh my God and you know all this stuff you could argue fed into this ethos at the time that resulted in people thinking that the Baptists thinking that the only principal thing to do was to give the the Russians the bomb um and so the the moral beliefs on this thing and the public discussion and the role that the inventors of this technology play this is the point of this book when they kind of take on this sort of public intellectual moral kind of thing it can have real consequences right because we live in a very different world today because Russia got the bomb than we would have lived in had they not gotten the bomb right the entire 20th century second half of the 20th century would have played out very different had those people not given Russia the bomb and so the stakes were very high then the good news today is nobody sitting here today I don't think worrying about like an analogous situation with respect to like I'm not really worried that Sam alman's going to decide to give you know the Chinese the design for AI although he did just speak in a Chinese conference which is interesting but however I I don't think I don't think that's what's at play here but what's at play here are all these other fundamental issues around what do we believe about this and then what laws and regulations and restrictions that we're going to put on it and and that's where I draw like a direct straight line and and anyway and my reading of the history on nukes is like the people who were doing the full hair shirt public this is awful this is terrible actually had like catastrophically bad results uh from from taking those views and that's what I'm worried it's going to happen again but is there a case to be made that you really need to wake the public up to the dangers of nuclear weapons when they were first dropped like really like educate them on like this is extremely dangerous and destructive weapon I think the education kind of happened quick and early like how it pretty obvious how we dropped one bomb and destroyed an entire city yeah so 880,000 people dead but uh and look but I don't like the reporting of that you can report that in all kinds of way War you can you can do all kinds of Slants like war is horrible war is terrible you can do you can make it seem like nuclear the use of nuclear weapons is just a part of war and all that kind of stuff something about the reporting and the discussion of nuclear weapons resulted in us being terrified in awe of the power of nuclear weapons and that potentially fed in a positive way towards the the game theory of mutually Shar destruction well so this gets to what actually H let's get to what actually Playing devil's advocate here yeah yeah sure of course let's get to what actually happened and then kind of back into that so what what actually happened I believe and again I think this is a reasonable reading of history is what actually happened was nukes then prevented World War II and they prevented World War III through the game theory of Mally assur destruction had nukes not existed right there would have been no reason why the cold war did not go hot right and then there and then you know in the military planners at the time right thought both on both sides thought that there was going to be World War III on the PLS of Europe and they thought there was going to be like 100 million people dead right it was like the most obvious thing in the world to happen right and it's the dog that didn't bark right like it may be like the best single net thing that happened in the entire 20th century is that like that didn't happen yeah actually just on that point you say a lot of really brilliant things it it it hit me just as you were saying it I don't know why it hit me for the first time but we got two Wars in a in a span of like uh 20 years like we could have kept getting more and more world wars and more and more ruthless it actually you could have had a US versus Russia War you could have by the way you have there's another hypothetical scenario the other hypothetical scenario is the Americans got the bomb the Russians didn't right and then America's the big dog and then maybe America would have had the capability to actually roll back the Aon curtain I don't know whether that would have happened but like it's entirely possible right and and and and the act of these people who had these moral positions about because they could forecast they could model they could forecast the future of how this technology would get used made a horrific mistake because they basically ensured that the Iron Curtain would continue for 50 years longer than it would have otherwise and again like these are counter facials I don't know that that's what what would have happened but like the decision to hand the bomb over was a big decision made by people who were very full of themselves yeah but so me as an America me as a person that loves America I also wonder if us was the only ones with the nuclear weapons uh that was the argument for handing the that was the was the guys who F the who handed over the bomb that was actually their moral argument yeah I would I would probably not hand it over to I I would be careful about the regimes you handed over to maybe give it to like the British or something or like uh like a democratically elected government well look there are people to this day who think that those spies Soviet spies did the right thing because they created a balance of Terror as opposed to the us having just and by the way let me let me balance of Terror let's tell the full version St such a sexy ring to it okay so the full version of the story is John Von noyman is a hero of both yours and mine the full version of story is he advocated for a first strike so when the US had the bomb and Russia did not he advocated for he said we we need to strike them right now strike Russia yeah yes what annoyment yes because he said World War I is inevitable um he was very hardcore uh he he his his theory was um his theory was World War III is inevitable we're definitely going to have World War I the only way to stop World War II is we have to take them out right now and we have to take them out right now before they get the bomb cuz this is our last chance now again like is this an example of philosophers in politics I don't know if that's in there or not but this is in the standard no but is meaning is this is on the other side so so most of the case studies most of the case studies in books like this are the crazy people on the left yeah um V noyman is a story arguably of the crazy people on the right um yeah stick to Computing John well this is the thing and this is this is the general principle get back to arore thing which is like I don't know whether any of these people should be making any of these calls yeah CU there's nothing in either vman's background or background or any of these people's background that qualifies them as moral authorities yeah well this actually brings up the point of in AI who are the good people to to reason about the morality the ethics the outside of these risks outside like the more complicated stuff that you you agree on is you know this will go into the hands of bad guys and all the kinds of ways they'll do is is interesting and dangerous um is dangerous in interesting unpredictable ways and who is the right person who are the right kinds of people to make decisions how to respond to it is it tech people so the history of these fields this is what he talks about in the book The History of these fields is that the the competence and capability and intelligence and training and accomplishments of senior scientists and technologists working on a technology and then being able to then make moral judgments on the use of the technology that track record is terrible that track that track record is like catastrophically bad um the people just the people that develop that technology are usually not going to be the right people well why would they so the claim is of course they're the knowledgeable ones but the problem is they've spent their entire life in a lab right they're not theologians but so what you find what you find when you read when you read this and when you look at these histories what you find is they generally are very thinly informed on History yeah on sociology on on on um theology on morality on ethics they they tend to manufacture their own worldviews from scratch they tend to be very sort of thin um they're not remotely the arguments that you would be having if you got like a group of Highly qualified theologians or philosophers or you know um well let me uh sort of uh as The Devil's Advocate takes a simple whiskey say that I I agree with uh with that but also it seems like the people who are doing kind of the ethics departments and these tech tech companies go sometimes the other way yes uh they're not nuanced on the on history or theology or this kind of stuff they it almost becomes a kind of outraged activism towards um directions that don't seem to be yeah grounded in history and uh humility and Nuance it's again drenched with arrogance so defitely I'm not sure which is worse well no they're both bad yeah so definitely not them either um so but I guess look this is a hard yeah it's a hard problem this a hard problem and this goes back to where we started which is okay who has the truth and it's like well um you know like how do societies arrive at like truth and how do we figure these things out and like our elected leaders play some role in it you know we all play some role in it um there have to be some set of public intellectuals at some point that bring you know rationality and judgment humility to it yeah those people are few and far between we should probably prize them very highly yeah C celebrate humility in our public leaders uh so getting to risk number two will AI ruin our society short version as you right if the murder robots don't get us the hate speech and misinformation will and uh the action you recommend in short don't let the thought police suppress AI well what is uh this risk of the effective misinformation of society that's going to be catalyzed by AI yeah so this is the social media this is what you just alluded to it's the activism kind of thing that's popped up in these companies in the industry and it's basically from my perspective it's basically part to of the war that played out over social media over the last 10 years um cuz you probably remember social media 10 years ago was basically who even wants this who wants who wants a photo of what your cat had for breakfast like this stuff is like silly and trivial and why can't these nerds like figure out how to invent something like useful and powerful and then you know certain things happened in the political system and then it sort of the polarity on that discussion switched all the way to social media is like the worst most corrosive most terrible most awful technology ever invented and it leads to you know terrible of the wrong you know politicians and policies and politics and like and all this stuff and and that that all got catalyzed into this very big kind of angry movement both inside and outside the companies to kind of bring social media to to heal and that got focused in particularly on two topics so-called hate speech and so-called misinformation um and and that's been this Saga playing out for the last for the last decade and and I don't even really want to even argue the pros and cons of the sides just to observe that that's been like a huge fight and has had you know big consequences to how these companies operate um basically that same those same sets of theories that same activist approach that same energy is being transplanted straight to Ai and you see that already happening it's why you know chat GPT will answer let's say certain questions and not others um it's why it gives you the can speech about you know whenever it starts with as a large language model I cannot you know basically means that somebody has reached in there and told it it can't talk about certain topics um do you think some of that is good so it's a it's an interesting question um so a couple couple observations um so so one is um the people who find this the most frustrating are the people who are worried about the murder robots right so so and in fact the the X So-Cal X risk people right they started with the term AI safety the term became AI alignment when the term became AI alignment is when this switch happened from we're worried it's going to kill us all to we're worried about hes specian misinformation sure the AI ex risk people have now renamed their thing uh AI not kill everyone ISM which I have to admit is a catchy term and they are very frustrated by the fact that the hate the sort of activist driven hate speech misinformation kind of thing is taking over which is what's happened is taken over the AI ethics field has been taken over by the hate speech misinformation people um you know look would I like to live in a world in which like everybody was nice to each other all the time and nobody ever said anything mean and nobody ever used a bad word and everything was always accurate and honest like that sounds great do I want to live in a world where there's like a centralized thought police working through the tech companies to enforce the view of a small set of Elites that they're going to determine what the rest of us think and feel like absolutely not there could be a middle ground somewhere like Wikipedia type of moderation there's moderation on Wikipedia that is somehow crowdsourced where don't have centralized Elites uh but it's also not completely just a free-for-all because uh the if you have the entirety of human knowledge at your fingertips you're going do a lot of harm like if you have a good assistant that's completely uncensored they can help you build a bomb they can help you um mess with people's physical well-being right if they because that information is out there on the internet so they're presumably there's it would be you could see the positives in um censoring some aspects of an AI model when it's helping you commit literal violence yeah and there's a section later section of the essay where I talk about bad people doing bad things yes right which which and there's there's a set of things that we should discuss there yeah um what happens in practice is these line as you alluded to this already these lines are not easy to draw and what what I've observed in the social media version of this is like the way I describe it is the slippery slope is not a fallacy it's an inevitability the minute you have this kind of activist personality gets in a position to make these decisions they they take it straight to Infinity like they it goes into the crazy Zone like almost immediately and never comes back because people become drunk with power um right and they they look if you're in the position to determine what the entire world thinks and feels and reads and says like you're going to take it and you know Elon has you know ventilated this with the Twitter files over the last you know three months and it's just like Crystal Clear like how bad it got there now yeah reason for optimism is what Elon is doing with the community notes um um so Community notes is actually a very interesting thing so what Elon is trying to do with Community notes um is he's trying to have it where there's only Community note when people who have previously disagreed on many topics agree on this one yes that's that's what that's what I'm trying to get at is like there's there could be Wikipedia like models or Community notes type of models where allows you to essentially either provide context or censor in a way that does not resist the slippery slope nature now there's another there's entirely different approach here which is basically um we have AIS that are producing content we could also have AIS that are consuming content yeah right and so one of the things that your assistant could do for you is help you consume all the content right and basically tell you when you're getting played so for example I'm going to want the AI that my kid uses right to be very you know child safe and I'm going to want it to filter for him all kinds of inappropriate stuff that he shouldn't be saying just because he's a kid yeah right and you see what I'm saying is you can Implement that you could you architecturally you could say you can solve this on the client side right solving on the server side gives you an opport opportunity to dictate for the entire world which I think is where you you take the slippery slope to hell um there's another architectural approach which is to solve this on the client side which is certainly what I would endorse it's AI risk number five will AI lead uh to bad people doing bad things I just imagine language models used to do so many bad things but the hope is there that you can have uh large language models used to then defend against it by more people by smarter people by um more effective people skilled people all that kind of stuff three three-part argument on bad people doing bad things um so um uh so number one right you can use the technology defensively and there's a we should be using AI to build like broads Spectrum vaccines and antibiotics for like bioweapons and we should be using AI to like hunt terrorists and catch criminals and like we should be doing like all kinds of stuff like that in in fact we should be doing those things even just to like go get like you know basically go eliminate risk from like regular pathogens that aren't like constructed by an AI so there's there's there's the whole um uh there's a whole defensive set of things um second is we have many laws on the books about the asual bad things right so it is actually illegal to be a you know to commit crimes to commit terrorist acts to you know build pathogens with the intent to deploy them to kill people and so we have those we we don't we actually don't need new laws for the vast majority of scenarios we actually already have the laws in the book on the books the third argument is the minute and this is sort of the foundational one that gets really tough but the minute you get into this thing which which you were kind of getting into which is like okay but like don't you need censorship sometimes right and don't you need restrictions sometimes it's like okay what is the cost of that um and particular in the world of Open Source right um and so um is open source AI going to be allowed or not um if open source AI is not allowed um then what is the regime that's going to be necessary legally and technically to prevent it from developing right and here again is where you get into and people have proposed that these kinds of things you get into I would say pretty extreme territory pretty fast do we have a monitor agent on every CPU and GPU that reports back to the government what we're doing with our computers are we seizing GPU clusters to get Beyond a certain size like and then by the way how are we doing all that globally right and like if China is developing an LM beyond the scale that we think is allowable are we going to invade right and you have figures on the ax risk side who are advocating any you know potentially up to nuclear strikes to prevent you know this kind of thing and so here you get into this thing and again you know you could maybe say this is you know you could even say this is what good bad or indiff or whatever but like here's the the comparison of nukes the comparison of nukes is very dangerous because one is just nukes were just just a b although we can come back to nuclear power but the other thing was like with nukes you could control plutonium right you could track plutonium and it was like hard to come by AI is just math and code right it's and it's in like math textbooks and it's like there are YouTube videos to teach you how to build it and like there's open there's already open source you know there a 40 billion preter model running around already called Falcon Online that anybody can download um and so okay you you walk down the logic path that says we need to have guard rails on this and you find yourself in a authoritarian totalitarian regime of thought control and machine control that would be so brutal that you would have destroyed the society that you're trying to protect and so I I I just don't see how that actually works so yeah you have to understand my brain is going full uh full steam ahead here because I agree with uh basically everything you're saying but I'm trying to play Devil's out here there because okay you highlighted the fact that there is a slippery slope to human nature the moment you censor something you start to censor everything uh that alignment starts out sounding nice but then you start to align to uh the beliefs of some select group of people and then it's just your beliefs the the the number the number of people you're aligning to is smaller and smaller as that group becomes more and more powerful okay but that just speaks to the people that censor are usually the assholes and uh the assholes get richer I wonder if it's possible to do without that for AI one way to ask this question is do you think the base models the the Bas the Baseline Foundation models should be open sourced like uh what what Mark Zuckerberg is saying they want to do so I look I mean I think it's totally appropriate that companies that are in the business of producing a product or service should be able to have a wide range of policies that they put right and I just again I want a heavily sensored model for my 8-year-old like I actually want that like like I would pay more money for the one that's more heavily censored than the one that's not right um and so like there are certainly scenarios where companies will make that decision look an interesting thing you brought up that or is is this really a speech issue um one of the things that the big tech companies are dealing with is that content generated uh from an llm is not covered under Section 230 uh which is the law that U protects internet platform companies from being sued for the user generated content um and so it it's actually yes and so there's actually there's actually a question I think there's still a question which is can big can American companies actually feel generative AI at all or is the liability actually going to just ultimately convince them that they can't do it because the minute the thing says something bad and it doesn't even need to be hate speech it could just be like an inac it could hallucinate a product you know detail on a vacuum cleaner you know and all of a sudden the vacuum cleaner company sues for misrepresentation and there's any symmetry there right because the the the LM is going to be producing billions of answers to questions and it only needs to get a few wrong so loss has to get updated really quick here yeah and nobody knows what to do with that right um so so anyway like there there there are big there are big questions around how companies operate at all so we we we talk about those but then there's this other question of like okay the open source so what about open source and and my answer to your question is kind of like obviously yes the models have there has to be full open source here because to live in a world in which that open source is not allowed is a world of draconian speech control human control machine control I mean you know black helicopters with Jack booted thugs coming out repelling down and seizing your GPU like territory well no no I'm 100% serious I that's you're saying slippery slope always leads there no no no no no no that's what's required to enforce it like how will you enforce a ban on open source you could add friction to it like harder to get the models cuz people will always be able to get the models but it'll be more in the shadows right the leading open source model right now is from the UAE like the next time they do that what do we do yeah like oh I see you're like U the 14-year-old in Indonesia comes out with a breakthrough mod you know we talked about most great software comes from a small number of people some kid comes out with some big new breakthrough and quantization or something and has some huge breakthrough and like what we going what are we going to like invade Indonesia and arrest him it seems like in terms of size of models and effectiveness of models the big tech companies will probably lead the way for quite a few years and and the question is of what policies they should use the the kid the kid in Indonesia should not be regulated but should Google meta uh Microsoft open AI be regulated well so but this goes okay so when does it become dangerous yeah right is is the danger that it's quote as powerful as the current leading commercial model or is it that it is it is just at some other arbitrary threshold yeah and then by the way like look how do we know like what we know today is that you need like a lot of money to like train these things but there are advances being made every week on training efficiency and you know data all kinds of synthetic you know look I don't even like the synthetic data thing we're talking about maybe some kid figures out a way to autogenerate synthetic data that's going to change everything yeah exactly and so like sitting here today like the the the Breakthrough just happened right you made this point like the Breakthrough just happened so we don't know what the shape of this technology is going to be I mean the big shock the big shock here is that you know whatever number of billions of parameters basically represents at least a very big percentage of human thought like who would have imagined that and then there's already work underway there was just this paper that just came out that basically takes a gpt3 scale model and compresses it down to run on a single 32 core CPU like who would predicted that yeah um you know some of these models now you can run on Raspberry pies like today they're very slow but like you know maybe they'll be a you know Pro you real perform you know like it's math and cod and here we're back here we're back dude it's math and code it's math and code it's math code and data it's bits Mark's just like walked away at this point he just screw it I don't know what to do with this you guys created this whole internet thing yeah yeah I'm a huge believer in open source here so my argument is we're going to have to see here's my argument is a my argument my full argument is AI is going to be like air it's going to be everywhere like it's this is just going to be in text it already is it's going to be in textbooks and kids are going to grow up knowing how to do this and it's just going to be a thing it's going to be in the air and you can't like pull this back anymore you can pull back air and so you just have to figure out how to live in this world right and then that that and then that's where I think like all this hand ringing about AI risk is basically complete waste of time because the the the effort should go into okay what are what what what is the defensive approach and so if you're worried about a you know AI generated pathogens the right thing to do is to have a permanent project warp speed right funded lavishly let's let's do a Manhattan let's talk about Manhattan let's do a Manhattan project for biological defense right and let's build AIS and let's have like broad spectrum vaccines where like we're insulated from every pathogen right and well the interesting thing is because of software a kid in his basement teenager could build like a system that defends against like the worst the worst I mean and to me defense is super exciting it's to like I If you believe in the good of human nature that most people want to do good to be the savior of humanity is really exciting yes not okay that's a dramatic statement but like to help people to help help people yeah okay what about just the jump around what about the risk of will AI lead to crippling inequality you know because we're kind of saying everybody's life will become better is it possible that the the rich get richer here yeah so this go this actually ironically goes back to Marxism so um because this was the so the core claim of Marxism right basically was that the owner the owners of capital would basically own the means of production and then over time they would basically accumulate all the wealth the workers would be paying in you know and getting nothing in return because they wouldn't be needed anymore right Marx was very worried about what he called mechanization or what later became known as automation um and that you know the workers would be am Miser and the the capitalists would end up with with with all and so this was one of the core core core principles of Marxism of course it turned out to be wrong about every previous wave of Technology um the reason it it turned out to be wrong about every previous wave of technology is that the way that the self-interested owner of the machines makes the most money is by providing the production capability in the form of products and services to the most people the most customers as possible Right the the largest this is one of those funny things where every CEO knows this intuitively and yet it's like hard to explain from the outside the the way you make the most money in any business is by selling to the largest market you can possibly get to the largest market you can possibly get to is everybody on the planet and so every large company does is everything that it can to drive down prices to be able to get volumes up to be able to get to everybody on the planet and that happened with everything from electricity it happened with telephones it happened with radio it happened with automobiles it happened with smartphones it happened with the PCS um it happened with the internet um it happened with mobile broadband um it's happened by the way with Coca-Cola it's happened with like every you know basically every industrially produced you know good or service people you want to drive it to the largest possible market and then as proof of that it's already happened right which is the early adopters of like CH GPT and bang are not like you know Exxon and Boeing they're you know your uncle and your nephew right it's just like fre it's either freely available online or it's available for 20 bucks a month or something but the you know these things went this this this technology went Mass Market immediately um and so look the the the owners of the means of production that whoever does this now mention these trillion dollar questions there are people who are going to get really rich doing this producing these things but they're going to get really rich by taking this technology to the broadest possible market so yes they'll get rich but they'll get rich having a huge positive impact yeah making the making the technology available to everybody yeah right and again smartphon same thing so there's this amazing kind of twist in um in business history which is you cannot spend $10,000 on a smartphone right you can't spend $100,000 you can't spend a like I would buy the million dollar smartphone like I'm signed up for it like if it's like suppose a million dollar smartphone was like much better than the Thousand smartphone like I'm there to buy it it doesn't exist why doesn't it exist Apple makes so much more money driving the price further down from $1,000 than they would trying to harvest right and so it's it's just this repeating pattern you see over and over again um where the and and and what's what's great about it what's great about it is you do not need to rely on anybody's enlightened right generosity to do this you just need to rely on capitalist self-interest uh what about AI taking our jobs yeah so very very similar thing here um there's sort of a there's a core fallacy which again was was very common in Marxism which is What's called the lump of Labor fallacy and this is sort of the fallacy that there's a only a fixed amount of work to be done in the world and if the and it's all being done today by people and then if machines do it there's no other work to be done um by people um and that's just a completely backwards view on how the economy develops and grows um because what happens is not in fact that what happens is the introduction of Technology into production process causes prices to fall as prices fall consumers have more spending power as consumers have more spending power they create new demand that new demand then causes capital and labor to form into new Enterprises to satisfy new wants and needs and the result is more jobs at higher wages so new wants and needs the the worry is that the the creation of new wants and needs at a rapid rate will mean there's a lot of turnover in jobs so people will lose jobs just the actual experience of losing a job and having to learn new things and new skills is painful for the individual two things one is the new jobs are often much better um so this actually came up that there was this Panic about a decade ago and all the truck drivers are going to lose their jobs right and number one that didn't happen because we haven't figured out a way to actually finish that yet but but the other thing was like like trick driver like I grew up in a town that was basically consisted of a truck stop right and I like knew a lot of truck drivers and like truck drivers live a decade shorter than everybody else like they it's a it's a it's actually like a very dangerous like they get like literally they have like higher rates of skin cancer and on the left side of their on the left side of their body from from being in the sun all the time the vibration of being in the truck is actually very damaging to your to your physiology and there's actually uh perhaps partially because of that reason uh there's a shortage yeah of uh people who want to be truck drivers yeah like it's not it's not like the always you want to ask somebody like that is do you want you know do you want your kid to be doing this job and like most of them will tell you no like I want my kid to be sitting in a cubicle somewhere like where they don't have this like where they don't die 10 years earlier and so so the new jobs number one the new jobs are often better but you don't get the new jobs until you go through the change and then to your point the the training thing you know it's always the issue is can can people adapt and again here you need to imagine living in a world in which everybody has the AI assistant capability right to be able to pick up new skills much more quickly and be able to have some you know be able to have a machine to work with to augment their skills it's still going to be painful but that's the process of life it's painful for some people I mean there's no look there's no question it's painful for some people and there you know yes it's not again I'm not a utopian on this and it's not like it's it's positive for everybody in the moment but it has been overwhelmingly positive for 300 years I mean look the concern here the concern the concern this concern has played out for for literally centuries um and you know this is the sort of Lite you know the story of the Lites um that you may remember there was a panic in the 2000s around Outsourcing was going to take all the jobs there was a panic in 2010s the robots were going to take all the jobs um in 2019 before covid we had more jobs at higher wages both in the country and in the world than at any point in human history and so the overwhelming evidence is that the net gain here is like just like wildly positive and most most people like overwhelmingly come out the other side being huge beneficiaries of this so you're right that the single greatest risk this is the risk you're most convinced by the single greatest risk of AI is that China wins global AI dominance and we the United States and the West do not can you elaborate yeah so this is the other thing which is a lot of the sort of AI risk debates today sort of assume that we're the only game in town right and so we have the ability to kind of sit in the United States and criticize ourselves and you know have our government like you know beat up on our companies and we figure out a way to restrict what our companies can do and you know we're goingon to you know we're going to ban this and ban that restrict this and do that and then there's this like other like force out there that like doesn't believe we have any power over them whatsoever and they have no desire to sign sign up for whatever rules we decide to put in place um and they're going to do whatever it is they're going to do and we have no control over it at all and it's China and specifically the Chinese Communist Party um and they have a completely publicized open you know U plan for what they're going to do with AI and it is not what we have in mind um and not only do they have that as a vision and a plan for their society but they also have it as a vision and plan for the rest of the world so their plan is what surveillance yeah authoritarian control so authoritarian population control um you know good oldfashioned communist authoritarian control um and surveillance and enforcement um and social credit scores and all the rest of it um and you are going to be monitored and metered within an inch of everything all the time um and it's going know it's basically the end of human freedom and that's their goal and you know they justify it on the basis of that's what leades to peace and you're worried that the uh regulating in the United States will will H progress enough to where uh the Chinese government would do win that race so their plan yeah yes yes and the reason for that is they and again they're very public on this they they have their plan is to proliferate their approach around the world um and they have this program called the digital Silk Road right which is building on their their Silk Road investment program and they've got their they've been laying they've been laying networking infrastructure all over the world with their 5G right work with their company Huawei and so they they've been laying all this fabric but financial and technological fabric all over the world and their plan is to roll out their vision of AI on top of that and to have every other country be running their version and then if you're a country prone to you know authoritarianism you're going to find this to be an incredible way to become more authoritarian uh if you're a country by the way not prone to authoritarianism you're going to have the Chinese Communist Party running your infrastructure and having back doors into it right which is also not good um now what's your sense of where they stand in terms of the race towards uh superintelligence as compared to the United States yeah so good news is they're behind but bad news is they you know they let's just say they get access to everything we do um so they're probably a year behind at each point in time but they get you know downloads I think of basically all of our work on a regular basis through a variety of means um and they are you know at Le we'll see they're at least putting out reports of very they just put out a report last week of a of a gpg 3.5 analog um they put out this report forget what it's called but um they put out this report of this LM they did and they they you know the way when open AI you know puts out they they they one of the ways they test you know GPT um is they they they run it through standardized exams like the sat right just how you can kind of gauge how smart it is uh and so Chinese report they ran their llm through uh the Chinese equivalent of the SAT um and it includes a section on Marxism um and a section on I sat tongue thought and it turns out their AI does very well on both of those topics right so like H this this alignment thing communist AI right like literal communist AI right and so their vision is like that's the you know so you know you can just imagine like you're a school you know you're a kid 10 years from now in Argentina or in Germany or in who knows where uh Indonesia and you ask the AI to explain to you like how the economy works and it gives you the most cheery upbeat explanation of Chinese style communism you've ever heard right so like the stakes here are like really big well my as we've been talking about my hope is not just with the United States but with just uh the kitten in his basement with open source LM CU I I don't know if I um trust large centralized institutions with super powerful Ai No matter what their ideology is uh power corrupts you've been investing in tech companies for about let's say 20 years and uh about 15 of which was uh with Andre Horwitz uh what interesting Trends in Tech have you seen over that time let's just talk about companies and just the evolution of the tech industry I mean the big shift over 20 years has been that Tech used to be a tools industry uh for basically from like 1940 through to about 2010 almost all the big successful companies were pix and shovels companies so PC database smartphone you know some some some tool that somebody else would pick up and use since 2010 most of the big wins have been in applications um so a company that starts a uh you know starts in an existing industry and goes directly to the customer in that industry and you know the early examples there were like uber and Lyft and Airbnb um and then that model is kind of elaborating out um oh uh the AI thing is actually a reversion on that for now cuz like most of the AI business right now is actually in Cloud provision of of of AI apis for other people to build on but but the big thing will probably be an app yeah I think I think most of the money I think probably will be in whatever yeah your AI financial adviser or your AI doctor or your AI lawyer or you know take your pick of whatever the domain is um and there and what's interesting is you know we the valley kind of does everything we we our the entrepreneurs kind of elaborate every possible idea and so there will be a set of companies that like make AI um something that can be purchased and used by a large law firms um and then there will be other companies that just go direct to Market as a as an AI lawyer what advice could you give for a startup founder just haven't seen so many successful companies so many companies that fail also what advice could you give to a startup founder someone who wants to build the next super successful startup in the tech space the Googles the apples the Twitter's yeah so the great thing about the really great Founders is they don't take any advice so so if you find yourself listening to advice maybe you shouldn't do it um well that's actually just to elaborate on that if you could also speak to Great Founders too like what what makes a great founder so what makes a great founder is super smart um coupled with super energetic coupled with super courageous I think it's some of those those three and intelligence passion and courage the first two are traits and the third one is a choice I think courage is a choice well because courage is a question of pain tolerance right um so um how how many times you willing to get punched in the face before you quit yeah um and here's maybe the biggest thing people don't understand about what it's like to be a startup founder is it get it gets very romanticized right um and even when it even when they fail it still gets romanticized about like what a great adventure it was but like the reality of it is most of what happens is people telling you no and then they usually follow that with you're stupid yeah right no I will not come to work for you um I will not leave my cushy job come work for you no I'm not going to buy your product you know no I'm not going to run a story about your company no I'm not this that the other thing um and so a huge amount of what people have to do is just get used to just getting punched and and and and the reason people don't understand this is because when you're a Founder you cannot let on that this is happening because it will cause people to think that you're weak and they'll lose faith in you yeah so you have to pretend that you're having a great time when you're dying inside right you're just in misery but why why did they do it why did they do oh yeah that's the thing it's it's like it is a level this actually one of the conclusions I think is I think it's actually for most of these people on a risk adjusted basis it's probably an irrational act they could probably be more financially successful on average if they just got like a real job at a big company um but there's you know some people just have an irrational need to do something new and build something for themselves and you know some people just can't tolerate having bosses oh here's the fun thing is how do you reference check Founders right so you call you know normal way you reference check you're hiring somebody is you call the bosses they're and you know and you find out if they were good employees and now you're trying to reference check Steve Jobs right it's like oh God he was terrible you know he was a terrible employee he never did what we told him to do yeah so what's a good reference if you want the previous boss to actually say there they never did what you told them to do that might be a good thing well ideally ideally what you want is I will go I I would like to go to work for that person um he worked for me here and now I'd like to work for him now unfortunately most people can't their egos can't can't handle that so they won't say that but that that that's the ideal what advice would you give to those folks in the space of intelligence passion and courage so I think the other big thing is you see people sometimes who say I want to start a company and then they kind of work through the process of coming up with an idea and generally those don't work as well as the case where somebody has the idea first and then they kind of realize that there's an opportunity to build a company and then they just turn out to be the right kind of person to do that when you say idea do you mean longterm big Vision or do you mean specifics of like product spec I would say specific like specifically what yes specifics like what is because for the first five years you don't get to have Vision you just got to build something people want and you got to figure out a way to sell it to them right it's very practical or you never get to Big Vision so so the first the first you have an idea of a set of products with the first product that can actually make some money yeah like it's got to work the first product's got to work by which I mean like it has to technically work but then it has to actually fit into the category and the customer mind of something that they want and then and then by the way the other part is they have to want to pay for it like somebody's got to pay the bills and so you got to figure out how to price it and whether you can actually extract the money yeah so usually it is much more predictable it's success is never predictable but it's more predictable if you start with a great idea and then back into starting the company um so this is what we did you know we had Mosaic before we had Netscape the Google guys had the Google search engine working at Stanford um right um the um uh you know yeah there's tons of examples where they you know Pier omad had eBay working before he left his previous job so I really love that idea of just having a thing the Prototype that actually works before you even begin to remotely scale yeah by the way it's also far easier to raise money right like the the ideal pitch that we receive is here's the thing that works would you like to invest in our company or not like that's so much easier than here's 30 slides mhm with a dream right um and then we have this concept called the idea maze which apology of came up with um when he was with us um so so so then there's this thing this goes to mythology which is um you know there's a mythology that kind of you know these these ideas um you know kind of arrive like magic or people kind of stumble into them it's like eBay with the pest dispensers or something um the reality you usually with the big successes is that the founder has been chewing on the problem for five or 10 years before they start the company and they often worked on it in school um or they even experimented on it when they were a kid um and they've been kind of training up over that period of time to be able to do the thing so they're like a true domain expert and and it sort of sounds like Mom and apple pie which is yeah you want to be a domain expert in what you're doing but you would you know the mythology is so strong of like oh I just like had this idea in the shower and now I'm doing it like it's generally not that no because well the maybe in the shower we had the exact product implementation details but yeah usually you're going to be for like years if not decades thinking about like everything around that well we call it the idea maze because the the idea maze basically is like there's all these permutations like for any IDE for any idea there's like all these different permutations who should the customer be what shape form should the product have and how should we take it to Market and all these things um and so um the really smart Founders have thought through all these scenarios by the time they go out to raise money um and they have like detailed answers on every one of those fronts because they put so much thought into it um the sort of the the the sort of more halfhazard Founders haven't thought about any any of that and it's the detailed ones who tend to do much better so how do you know when to take a leap if you have a cushy job or a happy life I mean the best reason is just because you can't tolerate not doing it right like this is the kind of thing where if you have to be advised into doing it you probably shouldn't do it um and so it's probably the opposite which is you just have such a burning sense of this has to be done I have to do this I have no choice what if it's going to lead to a lot of pain it's going to lead to a lot of pain I think that's what if it means uh losing sort of social relationships and damaging your um relationship with loved ones and all that kind of stuff yeah look so like it's going to put you in a social tunnel for sure right so you're going to like I you know there's this game you can play on Twitter which is you can do any whiff of the idea that there's uh basically any such thing as work life balance and that people should actually work hard and everybody gets mad but like the truth is like all the successful Founders are working 80 hour weeks and they're working you know they form very very strong social bonds with the people they work with they tend to lose a lot of friends in the outside or put those friendships on ice like that's just the nature of the of the thing um you know for most people that's worth the trade-off you know the advantage you know maybe younger Founders have is maybe they have less you know maybe they're not you know for example if they're not married yet or don't have kids yet that's an easier thing to bite off can you be an older founder yeah you definitely can yeah um yeah many of the most successful Founders are second third fourth time Founders they're in their 30s 40s 50s um the good news of being an older founder is you know more and you you know a lot more about what to do which is very helpful the problem is okay now you've got like a spouse and a family and kids and like you've got to go to the baseball game and like you can't go to the Bas you know and so it's it life is full of difficult choices Mark HRI uh you've written a blog post on what you've been up to uh you wrote this in October 2022 uh quote mostly I try to learn learn a lot for example the political events of 2014 to 2016 made clear to me that I didn't understand politics at all referencing maybe some of this this book here um so I deliberately withdrew from political engagement and fundraising and instead read my way back into history and as far to the political left and political right as I could so just high level question what's your approach to learning yeah so it's basically I would say it's it's autodidact um uh so it sort of goes it's going down the rabbit holes um so it's a combination so I kind of allude to it in that in that quote It's a combination of breadth and depth um and so I tend to yeah I tend I I go broad by the nature of what I do I go broad but then I tend to go deep in a rabbit hole for a while read everything I can and then come out of it and I might not I might not revisit that rabbit hole for you know another decade and in that blog post that I recommend people go check out you actually list a bunch of different books that you recommend on different topics on the American left and the American right uh it's just a lot of really good stuff the best explanation for the current structure of our society and politics you give two recommendations four books on the Spanish Civil War six books on deep history of the American right comprehensive by accuracies of Adolf Hitler uh one of which I read can recommend uh six books on the Deep history of the American left so American right American left looking at the history to give you the context um biography of uh Vladimir Lenin two of them uh on the French Revolution I actually have never read a biography on Lennon maybe that that would be useful everything's been so Marx focused the Sebastian biography of Lennon is extraordinary uh Victor Sebastian it'll blow your mind yeah so it's still useful to read incredible yeah it's incredible I actually think it's the single best book on the Soviet Union so that the perspective of Lenin is might be the best way to look at the Soviet Union versus Stalin versus Marx versus very interesting so two books on Fascism and anti-fascism uh by the same author Paul Godfrey uh brilliant book on the nature of mass movements and Collective psychology the definitive work on intellectual life under totalitarianism the captive mind uh the definitive worked on the Practical life under totalitarianism uh there's a bunch there's a bunch and the single best book first of all the list here is just incredible but you say the single best book I have found on who we are and how we got here is the ancient city uh by Numa Dennis FAL de kulanis I like it uh what's uh what did you learn about who we are as a human civilization from that book yeah so this is a fascinating book this one's free it's a free by the way it's it's a book from the 1860s you can download it or you can buy print out prints of it but um it's uh it was this guy who was a professor at the sban in the 1860s and he was apparently a savant on uh Antiquity on on Greek and Roman Antiquity um and the reason I say that is because his sources are 100% original Greek and Roman sources so he wrote a basically a history of Western Civilization from on the order of 4,000 years ago to basically the present times entirely working on original Greek and and Roman Roman sources um and what he was specifically trying to do was he was trying to reconstruct from the stories of the Greeks and the Romans he was trying to reconstruct what life in the west was like before the Greeks and the Romans which was in this in this in the civilization known as the the indo-europeans um and the short answer is and this is sort of Circa 4,000 you know 2000 BC to you know sort of 500 BC kind of that 1500 year stretch for civilization developed uh and his conclusion was basically Cults um they were basically Cults and the civilization was organized into Cults and the the intensity of the Cults was like a millionfold beyond anything that we would recognize today like it was a level of um all-encompassing belief and uh an action around religion um that was at a level of extremeness that we we wouldn't even recognize it um uh and and so specifically he tells the story of basically there were three levels of Cults there was the cult the tribal cult and then the city cult as as Society scaled up and then each cult was a joint Cult of uh family Gods which were ancestor gods and then nature Gods um and then your bonding into a family A Tribe or city was based on your adherence to that religion um people uh who were not of your family tribe City worshiped different gods which gave you not just the right with the responsibility to kill them on site right so they were serious about their Cults hardcore by the way shocking development I did not realize it zero concept of individual rights like even even up through the Greeks and even in the Romans they didn't have the concept of individual rights like the idea that as an individual you have like some right it's just like nope right and you look back and you're just like wow that's just like crazily like fascist in a degree that we wouldn't recognize today but it's like well they were living under extreme pressure for survival and you and you know the theory goes you could not have people running around making claims individual rights when you're just trying to get like your tribe through the winter right like you need like hardcore command and control and so and and actually what what if through a modern political lens those Cults were basically both fascist and communist um they were fascist in terms of social control and then they were communist in terms of economics but you think that's fundamentally that like pull towards uh cult is within us well so so my conclusion from this book so so so so the way we naturally think about the world we live in today is like we basically have such an improved version of everything that came before us right like we we have basically we've figured out all these things around morality and ethics and democracy and all these things and like they were basically stupid and retrograde and we like smart and sophisticated and we've improved all this um I I after reading that book uh I I now believe in many ways the opposite which is no actually we are still running in that original model we're just running in an incredibly diluted version of it so we're still running basically in Cults it's just our Cults are at like a thousandth or a millionth the level of intensity right and so our so just as to take religions you know the modern experience of a Christian in our time even somebody who considers him a devout Christian is just a shadow of the level of intensity of somebody who belonged to a religion back in that period and then by the way we have constru goes back to our AI discussion we we we we then sort of endlessly create new Cults like we're trying to fill the void right and the void is a void of of bonding okay living in their era like everybody living today transport in that era would view it as just completely intolerable in terms of like the the loss of freedom and the level of basically fascist control however every single person in that era and he really stresses this they knew exactly where they stood mhm they knew exactly where they belonged they knew exactly what their purpose was they knew exactly what they needed to do every day they knew exactly why they were doing it they had total certainty about their place in the universe so the question of meaning the question of purpose was very distinctly clearly defined for them absolutely overwhelmingly undisputably undeniably so as we turn the volume down on the cultism yes we start to uh the search for meaning starts getting harder and harder yes cuz we we don't have that we we are ungrounded we are we we are centered and and we all feel it right and that's why we reach for you know it's why we still reach for religion it's why we reach for you know we people start to take on you know let's say you know a faith and science maybe Beyond where they should put it uh you know and by the way like sports teams are like a you know they're like a tiny little version of a cult and you know you know Apple Keynotes are a tiny little version of a cult right and you know political you know yeah and there's cult you know there's full Cults on both sides of the political Spectrum right now right um you know operating in plain sight but still not full-blown compared to what it was compared to what it used I mean we would today consider full-blown but like yes they're they're at like I don't know 100 thousandth or something of the intensity of of what people had back then so so we live in a world today that in many ways is more advanced and moral and so forth and it's certainly a lot nicer much nicer world to live in but we live in a world that's like very washed out it's like everything has become very colorless and gray as compared to how people used to experience things which is I think why we're so prone to reach for drama we we there's something in US deeply evolved where we want that back and I wonder where it's all headed M as we turn the volume down more and more uh what advice would you give to Young Folks today uh in high school and college how to be successful in their career how to be successful in their life yeah so the tools that are available today I mean are just like I sometimes you know bore I sometimes bore uh you know kids by describing like what it was like to go look up a book you know to try to like discover a fact and you know in in the old days the 1970s 1980s go to the library and the card catalog and the whole thing you go through all that work and then the book is checked out you have to wait two weeks and like like to be in a world not only where you can get the answer to any question but also the world now you know the AI world where you've got like the assistant that will help you do anything help you teach learn anything like your ability both to learn and also to produce is just like I don't know a millionfold beyond what it used to be I have a I have a blog post I've been wanting to write um what should I call where where are the hyperproductive people um like good question right like with these tools like there should be authors that are writing like hundreds or thousands of like outstanding books well the authors there's a consumption question too but yeah well maybe not maybe not you're right but so the tools are much more powerful getting much more musicians right why aren't musicians producing a thousand times the number of songs right um like like the tools are spectacular so what uh what's the explanation and by way of advice like is motivation starting to be turned down a little bit or what I think it might be distraction distraction it's it's so easy to just sit consume um that I think people get distracted from production but if you wanted to um you know as a young person if you wanted to really stand out you could get on like a a hyper productivity curve very early on there's a great uh you know this story there's a great story in Roman history of Plenty the Elder who was this legendary Statesman um died in the vvus eruption trying to rescue his friends but um he was famous both for being a a sa basically being a polymath but also being an author and he wrote apparently like hundreds of books most of which have been lost but he like wrote all these encyclopedias and he literally like would be reading and writing all day long no matter what else is going on and he so he would like travel with like four slaves and two of them were responsible for reading to him and two of them were responsible for T taking dictation and so like he'd be going cross country and like literally he would be writing books like all the time and apparently they were spectacular there's only a few that have survived but apparently they were amazing so there's a lot of value to being somebody who finds focus in this life yeah like when and there are examples like there are uh you know there's this guy uh judge what's his name Posner Posner um who wrote like 40 books and was also federal judge um you know there's our friend bology I think is like this he's one of these you know where his output is just prodigious um and so it's like yeah I mean with these tools why not and I kind of think we're we're we're at this interesting kind of freeze frame moment where like this these tools are not in everybody's hands and everybody's just kind of staring at them trying to figure out what to do the new tools we have discovered fire yeah and trying to figure out how to use it to cook yeah right uh you told Tim Ferris that the perfect day is caffeine for 10 hours and alcohol for 4 hours you didn't think I'd be mentioning this did you uh it balances everything out perfectly as you said so perfect uh so let me ask what's what's the secret to balance and maybe to happiness in life um I I don't believe in Balance so I I I'm the wrong person ask can you elaborate why you don't believe in Balance I mean I maybe it's just and I I look I think people I think people are wired differently so I I think it's hard to generalize this kind of thing but I'm I am much happier and more satisfied when I'm fully committed to something so I'm very much in favor of it imbalance yeah imbalance and that applies to work to life to everything yeah no now I happen to have whatever Twist of personality traits lead that in non-destructive Dimensions including the fact that I've actually I now no longer do the 104 plan I I stopped drinking I do the caffeine but not the alcohol so there's something in my personality where I I I whatever maladaption I have is inclining me towards productive things not unproductive things so you're one of the wealthiest people in the world what's the relationship between wealth and happiness oh uh money and happiness so I think happiness I don't think happiness is the thing to strive for I think satisfaction is the thing that's that just sounds like happiness but turned down a bit no deeper so happiness is you know a walk in the woods at Sunset an ice cream cone MH a kiss um the first ice cream cone is great the thousandth ice cream cone not so much at some point the walks in the woods get boring what's the distinction between happiness and uh satisfaction I think satisfaction is a deeper thing which is like having found a purpose and fulfilling it being useful so just uh uh something that permeates all your days just this General contentment of of being useful that I'm fully satisfying my faculties that I'm fully delivering right uh on the gifts that I've been given that I'm you know net making the world better that I'm contributing to the people around me right and that I can look back and say wow that was hard but it was worth it I think generally seems to lead people in a better State than pursuit of pleasure pursuit of quote unquote happiness does money have do that they think the founders the founding fathers in the US threw this off-kilter when they use the phrase Pursuit of Happiness I think they should have said pursuit of satis said pursuit of satisfaction we might live in a better world today well you know they could have elaborated on a lot of things written about they could have tweaked the Second Amendment I think they were smarter than they realized they said you know what we're going to make it ambiguous and let these uh these humans figure out the rest these tribal cult like humans figure out the rest uh but money empowers that so I I think and I think there I mean look I think Elon is I don't think I'm even a great example but I think Elon would be the great example of this which is like you know look he's a guy who from every every day of his life from the day he started making money at all he just plows into into the into the next thing um and so I think I think money is definitely an enabler for satisfaction it was way money applied to happiness leads people down very dark paths yeah very destructive Avenues uh money applied to satisfaction I think could be is a real tool um I always by the way I was like you know El is the case study for Behavior but the other thing that always really made me think is Larry Larry pagee was asked one time what his approach to philanthropy was and he said oh I'm just my my philanthropic plan is just give all the money to Elon right uh well let me actually ask you about Elon what what are your um you've interacted with quite a lot of successful engineers and business people what do you think is special about Elon we talked about Steve Jobs what um what do you think is special about him as a leader as an innovator yeah so the the core of it is he's a he's he's back to the future so he he is he is doing the most leading edged things in the world but with an with a really deeply old school approach um and so to find comparisons to Elon you need to go to like Henry Ford and Thomas Watson and Howard Hughes and Andrew Carnegie right um Leland Stanford um John de Rockefeller right you need to go to the what we're called the bgea capital like the hardcore business owner operators who basically built you know indust basically built industrialized Society um Vanderbuilt um and it's a level of Hands-On commitment um and uh depth um in the business um coupled with an absolute priority uh towards truth um and towards um how to put it Science and Technology uh down to First principles that is just like absolute just like unbelievably absolute M he really is ideal that he's only ever talking to Engineers like he does not tolerate bullshit he has bullshit do anybody I've ever met um he wants ground truth on every single topic um and he runs his businesses directly day-to-day devoted to getting to ground truth in every single topic so uh you think it was a good decision for him to buy Twitter I have developed a view in life to not second guess Elon Musk I know this is going to sound crank crazy and unfounded but well I mean uh he's got a quite a track record I mean look the car was a crazy I mean the car was I mean look he's done a lot of things that seem crazy starting a new car company in the United States of America the last time somebody really tried to do that was the 1950s and it was called Tucker automotive and it was such a disaster they made a movie about what a disaster it was um and then Rockets like who does that like that's there's obviously no way to start a new rocket company like those days are over and then to do those at the same time so after he pulled those two off like okay fine like like this is one of my areas of like I whatever opinions I had about that it's just like okay clearly are not relevant like this is you just you at some point you just like better on the person and in general I wish more people would lean on celebrating and supporting versus deriding and destroying oh yeah I mean look he drives resentment like it's a resent like he he is a magnet for resentment um like his critics are the most miserable like resentful people in the world like it's almost a perfect match of like the the most idealized you know technologist you know of the century coupled with like just his critics are just bitter as can be I it's it's I mean it's it's sort of very Darkly comic to watch well he uh he fuels the fire of that by being an asshole on Twitter at times and which is fascinating to watch the drama of human civilization given our cult Roots just fully on fire he's running a cult you could say that very successfully so now now that our Cults have gone and we search for meaning what do you think is the meaning of this whole thing what's the meaning of life Mark andreon I don't know the answer to that um I think the meaning of uh of uh the closest I get to it is what I said about satisfaction so it's basically like okay we were given what we have like we should basically do our best what's the role of love in that mix I mean like what's the point of life if you're yeah without love like yeah so love is a big part of that satisfaction and look like taking care of people is like a wonderful thing like it you know a mentality you know there are pathological forms of taking care of people but there's also a very fundamental you know kind of aspect of taking care of people like for example I happen to be somebody who believes that capitalism and taking care of people are actually the they're actually the same thing um somebody once said capitalism is how you take care of people you don't know right um right and so like yeah I think it's like deeply woven into the whole thing um you know there's a long conversation to be had about that but yeah yeah creating products that are used by millions of people and bring them joy in small or big ways and then capitalism kind of enables that encourages that David fredman says there's only three ways to get somebody to do something for somebody else love money and force um Love and Money are better than Force that's a good ordering I think we we should bet on those try love first if that doesn't work then money yes and then Force well don't even try that one uh mark You're an incredible person I've been a huge fan I'm glad finally got a chance to talk I'm a fan of everything you do everything you do including on Twitter it's a huge honor to meet you to talk with you uh thanks again for doing this awesome thank you Al thanks for listening to this conversation with Mark andreon to support this podcast please check out our sponsors in the description and now let me leave you with some words to Mark HRI and himself the world is a very malleable place if you know what you want and you go for it with maximum energy and drive and passion the world will often reconfigure itself around you much more quickly and easily than you would think thank you for listening and hope to see you next time